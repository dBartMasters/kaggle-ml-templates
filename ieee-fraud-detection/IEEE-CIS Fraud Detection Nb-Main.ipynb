{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "# from scipy import stats\n",
    "import pickle\n",
    "# from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "import h2o\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=r'C:\\Users\\MasteD17189\\WORK\\personal\\kaggle git\\data\\ieee-fraud-detection'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_identity.csv imported shape:\t (144233, 41)\n"
     ]
    }
   ],
   "source": [
    "#id TRAIN\n",
    "id_train = pd.read_csv(data_path+'/train_identity.csv'\n",
    "#                              ,delimiter = '\\t'\n",
    "#                              ,dtype = {'OS: Type Description':str, 'Manufacturer Desc':str,\n",
    "#                                        'Quantity':float,'Fiscal Year Period (String)':str,'Contract Number':str,\n",
    "#                                       'Equipment':str}\n",
    "#                              ,parse_dates = ['DATETIME_CALL_RECEIVED']\n",
    "#                                ,compression='gzip'      \n",
    "#                                ,encoding='utf-8'\n",
    "                             ,low_memory=False\n",
    ")\n",
    "print('train_identity.csv imported shape:\\t',id_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_transaction.csv imported shape:\t (590540, 394)\n"
     ]
    }
   ],
   "source": [
    "#transaction TRAIN\n",
    "trans_train = pd.read_csv(data_path+'/train_transaction.csv'\n",
    "#                              ,delimiter = '\\t'\n",
    "#                              ,dtype = {'OS: Type Description':str, 'Manufacturer Desc':str,\n",
    "#                                        'Quantity':float,'Fiscal Year Period (String)':str,'Contract Number':str,\n",
    "#                                       'Equipment':str}\n",
    "#                              ,parse_dates = ['DATETIME_CALL_RECEIVED']\n",
    "#                                ,compression='gzip'      \n",
    "#                                ,encoding='utf-8'\n",
    "                             ,low_memory=False\n",
    ")\n",
    "print('train_transaction.csv imported shape:\\t',trans_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join the 2 data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_only     446307\n",
       "both          144233\n",
       "right_only         0\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join them\n",
    "train=trans_train.merge(id_train, on='TransactionID', how='left',indicator=True)\n",
    "#look at merge stats\n",
    "train._merge.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>D10</th>\n",
       "      <th>D11</th>\n",
       "      <th>D12</th>\n",
       "      <th>D13</th>\n",
       "      <th>D14</th>\n",
       "      <th>D15</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>V38</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>V41</th>\n",
       "      <th>V42</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V46</th>\n",
       "      <th>V47</th>\n",
       "      <th>V48</th>\n",
       "      <th>V49</th>\n",
       "      <th>V50</th>\n",
       "      <th>V51</th>\n",
       "      <th>V52</th>\n",
       "      <th>V53</th>\n",
       "      <th>V54</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "      <th>V65</th>\n",
       "      <th>V66</th>\n",
       "      <th>V67</th>\n",
       "      <th>V68</th>\n",
       "      <th>V69</th>\n",
       "      <th>V70</th>\n",
       "      <th>V71</th>\n",
       "      <th>V72</th>\n",
       "      <th>V73</th>\n",
       "      <th>V74</th>\n",
       "      <th>V75</th>\n",
       "      <th>V76</th>\n",
       "      <th>V77</th>\n",
       "      <th>V78</th>\n",
       "      <th>V79</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "      <th>V87</th>\n",
       "      <th>V88</th>\n",
       "      <th>V89</th>\n",
       "      <th>V90</th>\n",
       "      <th>V91</th>\n",
       "      <th>V92</th>\n",
       "      <th>V93</th>\n",
       "      <th>V94</th>\n",
       "      <th>V95</th>\n",
       "      <th>V96</th>\n",
       "      <th>V97</th>\n",
       "      <th>V98</th>\n",
       "      <th>V99</th>\n",
       "      <th>V100</th>\n",
       "      <th>V101</th>\n",
       "      <th>V102</th>\n",
       "      <th>V103</th>\n",
       "      <th>V104</th>\n",
       "      <th>V105</th>\n",
       "      <th>V106</th>\n",
       "      <th>V107</th>\n",
       "      <th>V108</th>\n",
       "      <th>V109</th>\n",
       "      <th>V110</th>\n",
       "      <th>V111</th>\n",
       "      <th>V112</th>\n",
       "      <th>V113</th>\n",
       "      <th>V114</th>\n",
       "      <th>V115</th>\n",
       "      <th>V116</th>\n",
       "      <th>V117</th>\n",
       "      <th>V118</th>\n",
       "      <th>V119</th>\n",
       "      <th>V120</th>\n",
       "      <th>V121</th>\n",
       "      <th>V122</th>\n",
       "      <th>V123</th>\n",
       "      <th>V124</th>\n",
       "      <th>V125</th>\n",
       "      <th>V126</th>\n",
       "      <th>V127</th>\n",
       "      <th>V128</th>\n",
       "      <th>V129</th>\n",
       "      <th>V130</th>\n",
       "      <th>V131</th>\n",
       "      <th>V132</th>\n",
       "      <th>V133</th>\n",
       "      <th>V134</th>\n",
       "      <th>V135</th>\n",
       "      <th>V136</th>\n",
       "      <th>V137</th>\n",
       "      <th>V138</th>\n",
       "      <th>V139</th>\n",
       "      <th>V140</th>\n",
       "      <th>V141</th>\n",
       "      <th>V142</th>\n",
       "      <th>V143</th>\n",
       "      <th>V144</th>\n",
       "      <th>V145</th>\n",
       "      <th>V146</th>\n",
       "      <th>V147</th>\n",
       "      <th>V148</th>\n",
       "      <th>V149</th>\n",
       "      <th>V150</th>\n",
       "      <th>V151</th>\n",
       "      <th>V152</th>\n",
       "      <th>V153</th>\n",
       "      <th>V154</th>\n",
       "      <th>V155</th>\n",
       "      <th>V156</th>\n",
       "      <th>V157</th>\n",
       "      <th>V158</th>\n",
       "      <th>V159</th>\n",
       "      <th>V160</th>\n",
       "      <th>V161</th>\n",
       "      <th>V162</th>\n",
       "      <th>V163</th>\n",
       "      <th>V164</th>\n",
       "      <th>V165</th>\n",
       "      <th>V166</th>\n",
       "      <th>V167</th>\n",
       "      <th>V168</th>\n",
       "      <th>V169</th>\n",
       "      <th>V170</th>\n",
       "      <th>V171</th>\n",
       "      <th>V172</th>\n",
       "      <th>V173</th>\n",
       "      <th>V174</th>\n",
       "      <th>V175</th>\n",
       "      <th>V176</th>\n",
       "      <th>V177</th>\n",
       "      <th>V178</th>\n",
       "      <th>V179</th>\n",
       "      <th>V180</th>\n",
       "      <th>V181</th>\n",
       "      <th>V182</th>\n",
       "      <th>V183</th>\n",
       "      <th>V184</th>\n",
       "      <th>V185</th>\n",
       "      <th>V186</th>\n",
       "      <th>V187</th>\n",
       "      <th>V188</th>\n",
       "      <th>V189</th>\n",
       "      <th>V190</th>\n",
       "      <th>V191</th>\n",
       "      <th>V192</th>\n",
       "      <th>V193</th>\n",
       "      <th>V194</th>\n",
       "      <th>V195</th>\n",
       "      <th>V196</th>\n",
       "      <th>V197</th>\n",
       "      <th>V198</th>\n",
       "      <th>V199</th>\n",
       "      <th>V200</th>\n",
       "      <th>V201</th>\n",
       "      <th>V202</th>\n",
       "      <th>V203</th>\n",
       "      <th>V204</th>\n",
       "      <th>V205</th>\n",
       "      <th>V206</th>\n",
       "      <th>V207</th>\n",
       "      <th>V208</th>\n",
       "      <th>V209</th>\n",
       "      <th>V210</th>\n",
       "      <th>V211</th>\n",
       "      <th>V212</th>\n",
       "      <th>V213</th>\n",
       "      <th>V214</th>\n",
       "      <th>V215</th>\n",
       "      <th>V216</th>\n",
       "      <th>V217</th>\n",
       "      <th>V218</th>\n",
       "      <th>V219</th>\n",
       "      <th>V220</th>\n",
       "      <th>V221</th>\n",
       "      <th>V222</th>\n",
       "      <th>V223</th>\n",
       "      <th>V224</th>\n",
       "      <th>V225</th>\n",
       "      <th>V226</th>\n",
       "      <th>V227</th>\n",
       "      <th>V228</th>\n",
       "      <th>V229</th>\n",
       "      <th>V230</th>\n",
       "      <th>V231</th>\n",
       "      <th>V232</th>\n",
       "      <th>V233</th>\n",
       "      <th>V234</th>\n",
       "      <th>V235</th>\n",
       "      <th>V236</th>\n",
       "      <th>V237</th>\n",
       "      <th>V238</th>\n",
       "      <th>V239</th>\n",
       "      <th>V240</th>\n",
       "      <th>V241</th>\n",
       "      <th>V242</th>\n",
       "      <th>V243</th>\n",
       "      <th>V244</th>\n",
       "      <th>V245</th>\n",
       "      <th>V246</th>\n",
       "      <th>V247</th>\n",
       "      <th>V248</th>\n",
       "      <th>V249</th>\n",
       "      <th>V250</th>\n",
       "      <th>V251</th>\n",
       "      <th>V252</th>\n",
       "      <th>V253</th>\n",
       "      <th>V254</th>\n",
       "      <th>V255</th>\n",
       "      <th>V256</th>\n",
       "      <th>V257</th>\n",
       "      <th>V258</th>\n",
       "      <th>V259</th>\n",
       "      <th>V260</th>\n",
       "      <th>V261</th>\n",
       "      <th>V262</th>\n",
       "      <th>V263</th>\n",
       "      <th>V264</th>\n",
       "      <th>V265</th>\n",
       "      <th>V266</th>\n",
       "      <th>V267</th>\n",
       "      <th>V268</th>\n",
       "      <th>V269</th>\n",
       "      <th>V270</th>\n",
       "      <th>V271</th>\n",
       "      <th>V272</th>\n",
       "      <th>V273</th>\n",
       "      <th>V274</th>\n",
       "      <th>V275</th>\n",
       "      <th>V276</th>\n",
       "      <th>V277</th>\n",
       "      <th>V278</th>\n",
       "      <th>V279</th>\n",
       "      <th>V280</th>\n",
       "      <th>V281</th>\n",
       "      <th>V282</th>\n",
       "      <th>V283</th>\n",
       "      <th>V284</th>\n",
       "      <th>V285</th>\n",
       "      <th>V286</th>\n",
       "      <th>V287</th>\n",
       "      <th>V288</th>\n",
       "      <th>V289</th>\n",
       "      <th>V290</th>\n",
       "      <th>V291</th>\n",
       "      <th>V292</th>\n",
       "      <th>V293</th>\n",
       "      <th>V294</th>\n",
       "      <th>V295</th>\n",
       "      <th>V296</th>\n",
       "      <th>V297</th>\n",
       "      <th>V298</th>\n",
       "      <th>V299</th>\n",
       "      <th>V300</th>\n",
       "      <th>V301</th>\n",
       "      <th>V302</th>\n",
       "      <th>V303</th>\n",
       "      <th>V304</th>\n",
       "      <th>V305</th>\n",
       "      <th>V306</th>\n",
       "      <th>V307</th>\n",
       "      <th>V308</th>\n",
       "      <th>V309</th>\n",
       "      <th>V310</th>\n",
       "      <th>V311</th>\n",
       "      <th>V312</th>\n",
       "      <th>V313</th>\n",
       "      <th>V314</th>\n",
       "      <th>V315</th>\n",
       "      <th>V316</th>\n",
       "      <th>V317</th>\n",
       "      <th>V318</th>\n",
       "      <th>V319</th>\n",
       "      <th>V320</th>\n",
       "      <th>V321</th>\n",
       "      <th>V322</th>\n",
       "      <th>V323</th>\n",
       "      <th>V324</th>\n",
       "      <th>V325</th>\n",
       "      <th>V326</th>\n",
       "      <th>V327</th>\n",
       "      <th>V328</th>\n",
       "      <th>V329</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "      <th>id_01</th>\n",
       "      <th>id_02</th>\n",
       "      <th>id_03</th>\n",
       "      <th>id_04</th>\n",
       "      <th>id_05</th>\n",
       "      <th>id_06</th>\n",
       "      <th>id_07</th>\n",
       "      <th>id_08</th>\n",
       "      <th>id_09</th>\n",
       "      <th>id_10</th>\n",
       "      <th>id_11</th>\n",
       "      <th>id_13</th>\n",
       "      <th>id_14</th>\n",
       "      <th>id_17</th>\n",
       "      <th>id_18</th>\n",
       "      <th>id_19</th>\n",
       "      <th>id_20</th>\n",
       "      <th>id_21</th>\n",
       "      <th>id_22</th>\n",
       "      <th>id_24</th>\n",
       "      <th>id_25</th>\n",
       "      <th>id_26</th>\n",
       "      <th>id_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.905400e+05</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>5.905400e+05</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>581607.000000</td>\n",
       "      <td>588975.000000</td>\n",
       "      <td>586281.000000</td>\n",
       "      <td>524834.000000</td>\n",
       "      <td>524834.000000</td>\n",
       "      <td>238269.000000</td>\n",
       "      <td>37627.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>589271.000000</td>\n",
       "      <td>309743.000000</td>\n",
       "      <td>327662.000000</td>\n",
       "      <td>421618.000000</td>\n",
       "      <td>280699.000000</td>\n",
       "      <td>73187.000000</td>\n",
       "      <td>38917.000000</td>\n",
       "      <td>74926.000000</td>\n",
       "      <td>74926.000000</td>\n",
       "      <td>514518.000000</td>\n",
       "      <td>311253.000000</td>\n",
       "      <td>64717.000000</td>\n",
       "      <td>61952.000000</td>\n",
       "      <td>62187.000000</td>\n",
       "      <td>501427.000000</td>\n",
       "      <td>311253.000000</td>\n",
       "      <td>311253.000000</td>\n",
       "      <td>311253.000000</td>\n",
       "      <td>311253.000000</td>\n",
       "      <td>311253.000000</td>\n",
       "      <td>311253.000000</td>\n",
       "      <td>311253.000000</td>\n",
       "      <td>311253.000000</td>\n",
       "      <td>311253.000000</td>\n",
       "      <td>311253.000000</td>\n",
       "      <td>311253.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>514467.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.00000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>421571.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>513444.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>501376.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.00000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>590226.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81951.000000</td>\n",
       "      <td>81951.000000</td>\n",
       "      <td>81951.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81951.000000</td>\n",
       "      <td>81951.000000</td>\n",
       "      <td>81951.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81951.000000</td>\n",
       "      <td>81951.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81945.000000</td>\n",
       "      <td>81951.000000</td>\n",
       "      <td>81951.000000</td>\n",
       "      <td>81951.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139819.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>139631.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>141416.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>130430.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>589271.000000</td>\n",
       "      <td>589271.000000</td>\n",
       "      <td>589271.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>589271.000000</td>\n",
       "      <td>589271.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>589271.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>589271.000000</td>\n",
       "      <td>589271.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>589271.000000</td>\n",
       "      <td>589271.000000</td>\n",
       "      <td>589271.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>590528.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.00000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>82351.000000</td>\n",
       "      <td>144233.000000</td>\n",
       "      <td>140872.000000</td>\n",
       "      <td>66324.000000</td>\n",
       "      <td>66324.000000</td>\n",
       "      <td>136865.000000</td>\n",
       "      <td>136865.000000</td>\n",
       "      <td>5155.000000</td>\n",
       "      <td>5155.000000</td>\n",
       "      <td>74926.000000</td>\n",
       "      <td>74926.000000</td>\n",
       "      <td>140978.000000</td>\n",
       "      <td>127320.000000</td>\n",
       "      <td>80044.000000</td>\n",
       "      <td>139369.000000</td>\n",
       "      <td>45113.000000</td>\n",
       "      <td>139318.000000</td>\n",
       "      <td>139261.000000</td>\n",
       "      <td>5159.000000</td>\n",
       "      <td>5169.000000</td>\n",
       "      <td>4747.000000</td>\n",
       "      <td>5132.000000</td>\n",
       "      <td>5163.000000</td>\n",
       "      <td>77586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.282270e+06</td>\n",
       "      <td>0.034990</td>\n",
       "      <td>7.372311e+06</td>\n",
       "      <td>135.027176</td>\n",
       "      <td>9898.734658</td>\n",
       "      <td>362.555488</td>\n",
       "      <td>153.194925</td>\n",
       "      <td>199.278897</td>\n",
       "      <td>290.733794</td>\n",
       "      <td>86.800630</td>\n",
       "      <td>118.502180</td>\n",
       "      <td>231.855423</td>\n",
       "      <td>14.092458</td>\n",
       "      <td>15.269734</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>4.092185</td>\n",
       "      <td>5.571526</td>\n",
       "      <td>9.071082</td>\n",
       "      <td>2.848478</td>\n",
       "      <td>5.144574</td>\n",
       "      <td>4.480240</td>\n",
       "      <td>5.240343</td>\n",
       "      <td>10.241521</td>\n",
       "      <td>4.076227</td>\n",
       "      <td>32.539918</td>\n",
       "      <td>8.295215</td>\n",
       "      <td>94.347568</td>\n",
       "      <td>169.563231</td>\n",
       "      <td>28.343348</td>\n",
       "      <td>140.002441</td>\n",
       "      <td>42.335965</td>\n",
       "      <td>69.805717</td>\n",
       "      <td>41.638950</td>\n",
       "      <td>146.058108</td>\n",
       "      <td>0.561057</td>\n",
       "      <td>123.982137</td>\n",
       "      <td>146.621465</td>\n",
       "      <td>54.037533</td>\n",
       "      <td>17.901295</td>\n",
       "      <td>57.724444</td>\n",
       "      <td>163.744579</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>1.045204</td>\n",
       "      <td>1.078075</td>\n",
       "      <td>0.846456</td>\n",
       "      <td>0.876991</td>\n",
       "      <td>1.045686</td>\n",
       "      <td>1.072870</td>\n",
       "      <td>1.027704</td>\n",
       "      <td>1.041529</td>\n",
       "      <td>0.463915</td>\n",
       "      <td>0.478987</td>\n",
       "      <td>0.559711</td>\n",
       "      <td>0.599166</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.122342</td>\n",
       "      <td>0.123460</td>\n",
       "      <td>0.134040</td>\n",
       "      <td>0.135363</td>\n",
       "      <td>0.816371</td>\n",
       "      <td>0.847843</td>\n",
       "      <td>0.129684</td>\n",
       "      <td>0.132292</td>\n",
       "      <td>1.034791</td>\n",
       "      <td>1.058097</td>\n",
       "      <td>0.977660</td>\n",
       "      <td>0.988040</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.387840</td>\n",
       "      <td>0.406436</td>\n",
       "      <td>0.140761</td>\n",
       "      <td>0.142417</td>\n",
       "      <td>0.130693</td>\n",
       "      <td>0.139154</td>\n",
       "      <td>0.542594</td>\n",
       "      <td>0.579198</td>\n",
       "      <td>1.108065</td>\n",
       "      <td>1.16240</td>\n",
       "      <td>0.166076</td>\n",
       "      <td>0.177145</td>\n",
       "      <td>0.999269</td>\n",
       "      <td>0.156118</td>\n",
       "      <td>0.168942</td>\n",
       "      <td>1.083891</td>\n",
       "      <td>1.120779</td>\n",
       "      <td>1.022286</td>\n",
       "      <td>1.038515</td>\n",
       "      <td>0.383174</td>\n",
       "      <td>0.397724</td>\n",
       "      <td>0.164746</td>\n",
       "      <td>0.170579</td>\n",
       "      <td>0.182695</td>\n",
       "      <td>0.577586</td>\n",
       "      <td>0.619982</td>\n",
       "      <td>1.067670</td>\n",
       "      <td>1.120979</td>\n",
       "      <td>0.128312</td>\n",
       "      <td>0.132453</td>\n",
       "      <td>0.134433</td>\n",
       "      <td>0.142537</td>\n",
       "      <td>0.829785</td>\n",
       "      <td>0.867563</td>\n",
       "      <td>0.130743</td>\n",
       "      <td>0.141825</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.981038</td>\n",
       "      <td>0.998121</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.390200</td>\n",
       "      <td>0.407924</td>\n",
       "      <td>0.140639</td>\n",
       "      <td>0.145124</td>\n",
       "      <td>0.139982</td>\n",
       "      <td>0.152147</td>\n",
       "      <td>0.544278</td>\n",
       "      <td>0.587557</td>\n",
       "      <td>1.086893</td>\n",
       "      <td>1.144462</td>\n",
       "      <td>0.136867</td>\n",
       "      <td>0.143954</td>\n",
       "      <td>0.152696</td>\n",
       "      <td>0.844610</td>\n",
       "      <td>0.881965</td>\n",
       "      <td>0.137145</td>\n",
       "      <td>0.149788</td>\n",
       "      <td>1.064885</td>\n",
       "      <td>1.099456</td>\n",
       "      <td>0.999246</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.401862</td>\n",
       "      <td>0.420461</td>\n",
       "      <td>0.150322</td>\n",
       "      <td>0.154812</td>\n",
       "      <td>0.137007</td>\n",
       "      <td>1.038019</td>\n",
       "      <td>3.00519</td>\n",
       "      <td>1.718933</td>\n",
       "      <td>0.061985</td>\n",
       "      <td>0.894986</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>0.889249</td>\n",
       "      <td>1.827229</td>\n",
       "      <td>1.279288</td>\n",
       "      <td>0.085433</td>\n",
       "      <td>0.281145</td>\n",
       "      <td>0.164584</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>1.004613</td>\n",
       "      <td>1.014816</td>\n",
       "      <td>1.007739</td>\n",
       "      <td>1.002563</td>\n",
       "      <td>1.005356</td>\n",
       "      <td>1.003383</td>\n",
       "      <td>1.009298</td>\n",
       "      <td>1.032450</td>\n",
       "      <td>1.015738</td>\n",
       "      <td>1.000391</td>\n",
       "      <td>1.001474</td>\n",
       "      <td>1.000729</td>\n",
       "      <td>1.000874</td>\n",
       "      <td>1.004276</td>\n",
       "      <td>1.001759</td>\n",
       "      <td>1.031120</td>\n",
       "      <td>1.092975</td>\n",
       "      <td>1.050415</td>\n",
       "      <td>129.979417</td>\n",
       "      <td>336.611559</td>\n",
       "      <td>204.094038</td>\n",
       "      <td>8.768944</td>\n",
       "      <td>92.165849</td>\n",
       "      <td>31.133302</td>\n",
       "      <td>103.513188</td>\n",
       "      <td>204.889160</td>\n",
       "      <td>145.972328</td>\n",
       "      <td>17.250132</td>\n",
       "      <td>38.821196</td>\n",
       "      <td>26.365090</td>\n",
       "      <td>0.036439</td>\n",
       "      <td>1.073915</td>\n",
       "      <td>1.125267</td>\n",
       "      <td>0.037696</td>\n",
       "      <td>0.048581</td>\n",
       "      <td>8.397006</td>\n",
       "      <td>3.708484</td>\n",
       "      <td>22.112946</td>\n",
       "      <td>0.156276</td>\n",
       "      <td>0.168601</td>\n",
       "      <td>0.765001</td>\n",
       "      <td>0.775313</td>\n",
       "      <td>277.598028</td>\n",
       "      <td>6.460190</td>\n",
       "      <td>9.432710</td>\n",
       "      <td>0.753200</td>\n",
       "      <td>0.757423</td>\n",
       "      <td>0.767381</td>\n",
       "      <td>0.777485</td>\n",
       "      <td>0.817573</td>\n",
       "      <td>0.833461</td>\n",
       "      <td>2719.299775</td>\n",
       "      <td>47453.181173</td>\n",
       "      <td>4.843938</td>\n",
       "      <td>6.594661</td>\n",
       "      <td>5.505955</td>\n",
       "      <td>877.888928</td>\n",
       "      <td>2239.912219</td>\n",
       "      <td>359.469437</td>\n",
       "      <td>3.929514</td>\n",
       "      <td>5.859501</td>\n",
       "      <td>0.168053</td>\n",
       "      <td>1.436779</td>\n",
       "      <td>1.690908</td>\n",
       "      <td>0.132012</td>\n",
       "      <td>0.055231</td>\n",
       "      <td>0.127794</td>\n",
       "      <td>0.212639</td>\n",
       "      <td>1.376979</td>\n",
       "      <td>3.529245</td>\n",
       "      <td>6.649283</td>\n",
       "      <td>4.869012</td>\n",
       "      <td>0.924123</td>\n",
       "      <td>0.253332</td>\n",
       "      <td>0.856243</td>\n",
       "      <td>0.484692</td>\n",
       "      <td>0.132364</td>\n",
       "      <td>0.173903</td>\n",
       "      <td>1.148799</td>\n",
       "      <td>1.843752</td>\n",
       "      <td>1.014755</td>\n",
       "      <td>1.038314</td>\n",
       "      <td>1.213083</td>\n",
       "      <td>1.058984</td>\n",
       "      <td>1.237361</td>\n",
       "      <td>1.149845</td>\n",
       "      <td>0.945773</td>\n",
       "      <td>0.954227</td>\n",
       "      <td>1.084580</td>\n",
       "      <td>0.949385</td>\n",
       "      <td>0.961951</td>\n",
       "      <td>1.270749</td>\n",
       "      <td>1.119977</td>\n",
       "      <td>1.159106</td>\n",
       "      <td>444.147142</td>\n",
       "      <td>1078.327538</td>\n",
       "      <td>686.956931</td>\n",
       "      <td>18.060417</td>\n",
       "      <td>6.189360</td>\n",
       "      <td>72.284098</td>\n",
       "      <td>8.888193</td>\n",
       "      <td>35.001872</td>\n",
       "      <td>14.391835</td>\n",
       "      <td>385.137037</td>\n",
       "      <td>765.988339</td>\n",
       "      <td>536.302802</td>\n",
       "      <td>38.437547</td>\n",
       "      <td>133.208217</td>\n",
       "      <td>71.107143</td>\n",
       "      <td>1.054619</td>\n",
       "      <td>1.725784</td>\n",
       "      <td>1.367132</td>\n",
       "      <td>0.169472</td>\n",
       "      <td>1.274912</td>\n",
       "      <td>1.359005</td>\n",
       "      <td>0.093153</td>\n",
       "      <td>0.394748</td>\n",
       "      <td>0.191758</td>\n",
       "      <td>0.247612</td>\n",
       "      <td>0.147975</td>\n",
       "      <td>1.351928</td>\n",
       "      <td>1.638710</td>\n",
       "      <td>1.465476</td>\n",
       "      <td>0.765506</td>\n",
       "      <td>1.005597</td>\n",
       "      <td>0.908388</td>\n",
       "      <td>2.092847</td>\n",
       "      <td>0.184106</td>\n",
       "      <td>0.307667</td>\n",
       "      <td>0.253500</td>\n",
       "      <td>0.127956</td>\n",
       "      <td>0.136965</td>\n",
       "      <td>1.000997</td>\n",
       "      <td>1.000238</td>\n",
       "      <td>1.113463</td>\n",
       "      <td>1.178387</td>\n",
       "      <td>1.118562</td>\n",
       "      <td>0.876619</td>\n",
       "      <td>1.183723</td>\n",
       "      <td>1.025355</td>\n",
       "      <td>1.069493</td>\n",
       "      <td>1.042851</td>\n",
       "      <td>0.788588</td>\n",
       "      <td>0.794231</td>\n",
       "      <td>1.032048</td>\n",
       "      <td>1.162164</td>\n",
       "      <td>1.075113</td>\n",
       "      <td>0.806656</td>\n",
       "      <td>0.814950</td>\n",
       "      <td>1.250993</td>\n",
       "      <td>1.343510</td>\n",
       "      <td>0.967832</td>\n",
       "      <td>0.964425</td>\n",
       "      <td>1.107161</td>\n",
       "      <td>1.013279</td>\n",
       "      <td>117.390676</td>\n",
       "      <td>201.657617</td>\n",
       "      <td>153.520534</td>\n",
       "      <td>9.167839</td>\n",
       "      <td>36.525103</td>\n",
       "      <td>18.813407</td>\n",
       "      <td>5.997508</td>\n",
       "      <td>7.712764</td>\n",
       "      <td>9.445133</td>\n",
       "      <td>8.464571</td>\n",
       "      <td>73.825549</td>\n",
       "      <td>107.151636</td>\n",
       "      <td>88.899939</td>\n",
       "      <td>31.797277</td>\n",
       "      <td>51.956645</td>\n",
       "      <td>42.328228</td>\n",
       "      <td>1.123061</td>\n",
       "      <td>1.967082</td>\n",
       "      <td>0.087783</td>\n",
       "      <td>0.817171</td>\n",
       "      <td>0.991114</td>\n",
       "      <td>0.088543</td>\n",
       "      <td>1.167660</td>\n",
       "      <td>0.031492</td>\n",
       "      <td>0.358579</td>\n",
       "      <td>0.184350</td>\n",
       "      <td>0.235975</td>\n",
       "      <td>1.103011</td>\n",
       "      <td>1.659811</td>\n",
       "      <td>1.239916</td>\n",
       "      <td>0.942599</td>\n",
       "      <td>2.313863</td>\n",
       "      <td>1.433424</td>\n",
       "      <td>0.328917</td>\n",
       "      <td>0.089034</td>\n",
       "      <td>0.298829</td>\n",
       "      <td>0.171655</td>\n",
       "      <td>0.045507</td>\n",
       "      <td>0.052002</td>\n",
       "      <td>0.251761</td>\n",
       "      <td>0.283140</td>\n",
       "      <td>0.264208</td>\n",
       "      <td>1.000007</td>\n",
       "      <td>139.748713</td>\n",
       "      <td>408.682375</td>\n",
       "      <td>230.413180</td>\n",
       "      <td>10.995986</td>\n",
       "      <td>118.195658</td>\n",
       "      <td>4.202175</td>\n",
       "      <td>39.173910</td>\n",
       "      <td>21.351473</td>\n",
       "      <td>43.319174</td>\n",
       "      <td>26.806977</td>\n",
       "      <td>109.818544</td>\n",
       "      <td>247.606741</td>\n",
       "      <td>162.153398</td>\n",
       "      <td>18.372476</td>\n",
       "      <td>42.073133</td>\n",
       "      <td>28.326584</td>\n",
       "      <td>6.220289</td>\n",
       "      <td>13.103775</td>\n",
       "      <td>9.184612</td>\n",
       "      <td>0.058494</td>\n",
       "      <td>0.851040</td>\n",
       "      <td>0.296633</td>\n",
       "      <td>0.336790</td>\n",
       "      <td>1.312844</td>\n",
       "      <td>0.775874</td>\n",
       "      <td>721.741883</td>\n",
       "      <td>1375.783644</td>\n",
       "      <td>1014.622782</td>\n",
       "      <td>9.807015</td>\n",
       "      <td>59.16455</td>\n",
       "      <td>28.530903</td>\n",
       "      <td>55.352422</td>\n",
       "      <td>151.160542</td>\n",
       "      <td>100.700882</td>\n",
       "      <td>-10.170502</td>\n",
       "      <td>174716.584708</td>\n",
       "      <td>0.060189</td>\n",
       "      <td>-0.058938</td>\n",
       "      <td>1.615585</td>\n",
       "      <td>-6.698710</td>\n",
       "      <td>13.285354</td>\n",
       "      <td>-38.600388</td>\n",
       "      <td>0.091023</td>\n",
       "      <td>-0.301124</td>\n",
       "      <td>99.745325</td>\n",
       "      <td>48.053071</td>\n",
       "      <td>-344.507146</td>\n",
       "      <td>189.451377</td>\n",
       "      <td>14.237337</td>\n",
       "      <td>353.128174</td>\n",
       "      <td>403.882666</td>\n",
       "      <td>368.269820</td>\n",
       "      <td>16.002708</td>\n",
       "      <td>12.800927</td>\n",
       "      <td>329.608924</td>\n",
       "      <td>149.070308</td>\n",
       "      <td>26.508597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.704744e+05</td>\n",
       "      <td>0.183755</td>\n",
       "      <td>4.617224e+06</td>\n",
       "      <td>239.162522</td>\n",
       "      <td>4901.170153</td>\n",
       "      <td>157.793246</td>\n",
       "      <td>11.336444</td>\n",
       "      <td>41.244453</td>\n",
       "      <td>101.741072</td>\n",
       "      <td>2.690623</td>\n",
       "      <td>371.872026</td>\n",
       "      <td>529.053494</td>\n",
       "      <td>133.569018</td>\n",
       "      <td>154.668899</td>\n",
       "      <td>0.150536</td>\n",
       "      <td>68.848459</td>\n",
       "      <td>25.786976</td>\n",
       "      <td>71.508467</td>\n",
       "      <td>61.727304</td>\n",
       "      <td>95.378574</td>\n",
       "      <td>16.674897</td>\n",
       "      <td>95.581443</td>\n",
       "      <td>94.336292</td>\n",
       "      <td>86.666218</td>\n",
       "      <td>129.364844</td>\n",
       "      <td>49.544262</td>\n",
       "      <td>157.660387</td>\n",
       "      <td>177.315865</td>\n",
       "      <td>62.384721</td>\n",
       "      <td>191.096774</td>\n",
       "      <td>89.000144</td>\n",
       "      <td>143.669253</td>\n",
       "      <td>99.743264</td>\n",
       "      <td>231.663840</td>\n",
       "      <td>0.316880</td>\n",
       "      <td>182.615225</td>\n",
       "      <td>186.042622</td>\n",
       "      <td>124.274558</td>\n",
       "      <td>67.614425</td>\n",
       "      <td>136.312450</td>\n",
       "      <td>202.726660</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>0.240133</td>\n",
       "      <td>0.320890</td>\n",
       "      <td>0.440053</td>\n",
       "      <td>0.475902</td>\n",
       "      <td>0.239385</td>\n",
       "      <td>0.304779</td>\n",
       "      <td>0.186069</td>\n",
       "      <td>0.226339</td>\n",
       "      <td>0.521522</td>\n",
       "      <td>0.552431</td>\n",
       "      <td>0.510533</td>\n",
       "      <td>0.532185</td>\n",
       "      <td>0.022345</td>\n",
       "      <td>0.332422</td>\n",
       "      <td>0.342841</td>\n",
       "      <td>0.364456</td>\n",
       "      <td>0.371763</td>\n",
       "      <td>0.425512</td>\n",
       "      <td>0.459451</td>\n",
       "      <td>0.339060</td>\n",
       "      <td>0.359415</td>\n",
       "      <td>0.247681</td>\n",
       "      <td>0.305485</td>\n",
       "      <td>0.185245</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.028596</td>\n",
       "      <td>0.031133</td>\n",
       "      <td>0.510652</td>\n",
       "      <td>0.554311</td>\n",
       "      <td>0.355793</td>\n",
       "      <td>0.368278</td>\n",
       "      <td>0.340900</td>\n",
       "      <td>0.357549</td>\n",
       "      <td>0.516010</td>\n",
       "      <td>0.539039</td>\n",
       "      <td>0.690571</td>\n",
       "      <td>0.85892</td>\n",
       "      <td>0.451956</td>\n",
       "      <td>0.505786</td>\n",
       "      <td>0.027020</td>\n",
       "      <td>0.382896</td>\n",
       "      <td>0.433359</td>\n",
       "      <td>0.639143</td>\n",
       "      <td>0.729774</td>\n",
       "      <td>0.166719</td>\n",
       "      <td>0.231862</td>\n",
       "      <td>0.508189</td>\n",
       "      <td>0.542654</td>\n",
       "      <td>0.373995</td>\n",
       "      <td>0.403899</td>\n",
       "      <td>0.439002</td>\n",
       "      <td>0.511571</td>\n",
       "      <td>0.534635</td>\n",
       "      <td>0.391364</td>\n",
       "      <td>0.661129</td>\n",
       "      <td>0.349094</td>\n",
       "      <td>0.372907</td>\n",
       "      <td>0.379291</td>\n",
       "      <td>0.418230</td>\n",
       "      <td>0.436617</td>\n",
       "      <td>0.483803</td>\n",
       "      <td>0.355262</td>\n",
       "      <td>0.406157</td>\n",
       "      <td>0.018353</td>\n",
       "      <td>0.216235</td>\n",
       "      <td>0.245912</td>\n",
       "      <td>0.023760</td>\n",
       "      <td>0.513696</td>\n",
       "      <td>0.554499</td>\n",
       "      <td>0.364303</td>\n",
       "      <td>0.389212</td>\n",
       "      <td>0.367098</td>\n",
       "      <td>0.393274</td>\n",
       "      <td>0.514318</td>\n",
       "      <td>0.538230</td>\n",
       "      <td>0.532958</td>\n",
       "      <td>0.781474</td>\n",
       "      <td>0.379904</td>\n",
       "      <td>0.409932</td>\n",
       "      <td>0.452298</td>\n",
       "      <td>0.422529</td>\n",
       "      <td>0.470757</td>\n",
       "      <td>0.361875</td>\n",
       "      <td>0.419445</td>\n",
       "      <td>0.419807</td>\n",
       "      <td>0.511281</td>\n",
       "      <td>0.027447</td>\n",
       "      <td>0.031943</td>\n",
       "      <td>0.516153</td>\n",
       "      <td>0.561865</td>\n",
       "      <td>0.375682</td>\n",
       "      <td>0.402314</td>\n",
       "      <td>0.343878</td>\n",
       "      <td>21.034304</td>\n",
       "      <td>40.23949</td>\n",
       "      <td>27.700449</td>\n",
       "      <td>0.284995</td>\n",
       "      <td>2.722552</td>\n",
       "      <td>0.947176</td>\n",
       "      <td>20.582571</td>\n",
       "      <td>35.928456</td>\n",
       "      <td>25.685642</td>\n",
       "      <td>0.648718</td>\n",
       "      <td>3.373948</td>\n",
       "      <td>1.825665</td>\n",
       "      <td>0.020494</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>0.127769</td>\n",
       "      <td>0.097290</td>\n",
       "      <td>0.070830</td>\n",
       "      <td>0.084617</td>\n",
       "      <td>0.074754</td>\n",
       "      <td>0.110179</td>\n",
       "      <td>0.190385</td>\n",
       "      <td>0.136770</td>\n",
       "      <td>0.035238</td>\n",
       "      <td>0.041011</td>\n",
       "      <td>0.036392</td>\n",
       "      <td>0.041684</td>\n",
       "      <td>0.067097</td>\n",
       "      <td>0.048636</td>\n",
       "      <td>0.228134</td>\n",
       "      <td>0.374103</td>\n",
       "      <td>0.280037</td>\n",
       "      <td>2346.951681</td>\n",
       "      <td>4238.666949</td>\n",
       "      <td>3010.258774</td>\n",
       "      <td>113.832828</td>\n",
       "      <td>315.960485</td>\n",
       "      <td>161.161258</td>\n",
       "      <td>2266.106140</td>\n",
       "      <td>3796.316755</td>\n",
       "      <td>2772.986817</td>\n",
       "      <td>293.847563</td>\n",
       "      <td>451.808411</td>\n",
       "      <td>348.332714</td>\n",
       "      <td>0.428490</td>\n",
       "      <td>1.333924</td>\n",
       "      <td>1.467850</td>\n",
       "      <td>0.215133</td>\n",
       "      <td>0.313888</td>\n",
       "      <td>55.267545</td>\n",
       "      <td>10.485633</td>\n",
       "      <td>64.371860</td>\n",
       "      <td>0.682328</td>\n",
       "      <td>0.750497</td>\n",
       "      <td>0.581425</td>\n",
       "      <td>0.628191</td>\n",
       "      <td>829.576922</td>\n",
       "      <td>15.232324</td>\n",
       "      <td>21.554486</td>\n",
       "      <td>0.532649</td>\n",
       "      <td>0.546907</td>\n",
       "      <td>0.602678</td>\n",
       "      <td>0.647209</td>\n",
       "      <td>0.682016</td>\n",
       "      <td>0.734336</td>\n",
       "      <td>8355.445049</td>\n",
       "      <td>142076.069162</td>\n",
       "      <td>58.929757</td>\n",
       "      <td>69.195180</td>\n",
       "      <td>63.077887</td>\n",
       "      <td>6049.166505</td>\n",
       "      <td>8223.258928</td>\n",
       "      <td>1244.463270</td>\n",
       "      <td>42.200980</td>\n",
       "      <td>54.032468</td>\n",
       "      <td>0.904944</td>\n",
       "      <td>1.751143</td>\n",
       "      <td>2.444748</td>\n",
       "      <td>0.924894</td>\n",
       "      <td>0.264439</td>\n",
       "      <td>0.379763</td>\n",
       "      <td>0.857133</td>\n",
       "      <td>1.829420</td>\n",
       "      <td>41.310622</td>\n",
       "      <td>69.447364</td>\n",
       "      <td>50.489426</td>\n",
       "      <td>6.112630</td>\n",
       "      <td>1.248974</td>\n",
       "      <td>5.792934</td>\n",
       "      <td>2.946982</td>\n",
       "      <td>0.543699</td>\n",
       "      <td>0.699733</td>\n",
       "      <td>1.223529</td>\n",
       "      <td>9.884390</td>\n",
       "      <td>0.671207</td>\n",
       "      <td>0.792528</td>\n",
       "      <td>1.480318</td>\n",
       "      <td>0.677527</td>\n",
       "      <td>2.635961</td>\n",
       "      <td>1.714792</td>\n",
       "      <td>0.304158</td>\n",
       "      <td>0.376420</td>\n",
       "      <td>1.105834</td>\n",
       "      <td>0.336871</td>\n",
       "      <td>0.493065</td>\n",
       "      <td>1.671863</td>\n",
       "      <td>1.253853</td>\n",
       "      <td>1.418618</td>\n",
       "      <td>4683.828419</td>\n",
       "      <td>9105.607991</td>\n",
       "      <td>6048.980716</td>\n",
       "      <td>266.545451</td>\n",
       "      <td>191.474014</td>\n",
       "      <td>925.676660</td>\n",
       "      <td>59.047125</td>\n",
       "      <td>250.800822</td>\n",
       "      <td>86.523724</td>\n",
       "      <td>4541.837915</td>\n",
       "      <td>7496.120737</td>\n",
       "      <td>5471.664736</td>\n",
       "      <td>571.834283</td>\n",
       "      <td>1040.453748</td>\n",
       "      <td>680.267625</td>\n",
       "      <td>9.547354</td>\n",
       "      <td>13.919876</td>\n",
       "      <td>12.044032</td>\n",
       "      <td>1.002463</td>\n",
       "      <td>2.728792</td>\n",
       "      <td>2.913772</td>\n",
       "      <td>0.402232</td>\n",
       "      <td>3.443310</td>\n",
       "      <td>1.290820</td>\n",
       "      <td>2.756449</td>\n",
       "      <td>2.049363</td>\n",
       "      <td>1.409722</td>\n",
       "      <td>4.316026</td>\n",
       "      <td>2.122783</td>\n",
       "      <td>8.877119</td>\n",
       "      <td>10.460253</td>\n",
       "      <td>10.149884</td>\n",
       "      <td>11.323036</td>\n",
       "      <td>0.902639</td>\n",
       "      <td>2.152332</td>\n",
       "      <td>1.716634</td>\n",
       "      <td>0.574657</td>\n",
       "      <td>0.616260</td>\n",
       "      <td>0.049522</td>\n",
       "      <td>0.022663</td>\n",
       "      <td>0.660110</td>\n",
       "      <td>1.398953</td>\n",
       "      <td>0.698807</td>\n",
       "      <td>1.821065</td>\n",
       "      <td>1.040363</td>\n",
       "      <td>0.281604</td>\n",
       "      <td>0.888341</td>\n",
       "      <td>0.528812</td>\n",
       "      <td>0.488386</td>\n",
       "      <td>0.501240</td>\n",
       "      <td>0.389546</td>\n",
       "      <td>3.612553</td>\n",
       "      <td>1.357550</td>\n",
       "      <td>0.939124</td>\n",
       "      <td>0.969953</td>\n",
       "      <td>1.299956</td>\n",
       "      <td>2.015811</td>\n",
       "      <td>2.113447</td>\n",
       "      <td>0.379828</td>\n",
       "      <td>1.323230</td>\n",
       "      <td>0.625455</td>\n",
       "      <td>1294.851543</td>\n",
       "      <td>2284.827492</td>\n",
       "      <td>1605.512276</td>\n",
       "      <td>208.038863</td>\n",
       "      <td>644.878586</td>\n",
       "      <td>311.280181</td>\n",
       "      <td>207.317539</td>\n",
       "      <td>65.507232</td>\n",
       "      <td>74.147726</td>\n",
       "      <td>69.723735</td>\n",
       "      <td>935.187927</td>\n",
       "      <td>1258.734139</td>\n",
       "      <td>1072.883139</td>\n",
       "      <td>615.659714</td>\n",
       "      <td>732.145368</td>\n",
       "      <td>660.611820</td>\n",
       "      <td>21.021950</td>\n",
       "      <td>27.851780</td>\n",
       "      <td>0.512748</td>\n",
       "      <td>0.921880</td>\n",
       "      <td>1.558731</td>\n",
       "      <td>0.338424</td>\n",
       "      <td>3.282454</td>\n",
       "      <td>0.190939</td>\n",
       "      <td>1.078995</td>\n",
       "      <td>0.430989</td>\n",
       "      <td>0.599231</td>\n",
       "      <td>0.768897</td>\n",
       "      <td>16.252538</td>\n",
       "      <td>3.775050</td>\n",
       "      <td>20.588816</td>\n",
       "      <td>39.526468</td>\n",
       "      <td>25.962948</td>\n",
       "      <td>3.264745</td>\n",
       "      <td>0.628352</td>\n",
       "      <td>3.175062</td>\n",
       "      <td>1.724218</td>\n",
       "      <td>0.289573</td>\n",
       "      <td>0.318310</td>\n",
       "      <td>0.481889</td>\n",
       "      <td>0.623608</td>\n",
       "      <td>0.528238</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>2348.849634</td>\n",
       "      <td>4391.992977</td>\n",
       "      <td>3021.924247</td>\n",
       "      <td>116.254277</td>\n",
       "      <td>352.983093</td>\n",
       "      <td>102.374938</td>\n",
       "      <td>172.128339</td>\n",
       "      <td>95.902970</td>\n",
       "      <td>173.619028</td>\n",
       "      <td>116.853222</td>\n",
       "      <td>2270.033202</td>\n",
       "      <td>3980.042828</td>\n",
       "      <td>2793.343636</td>\n",
       "      <td>332.304848</td>\n",
       "      <td>473.499307</td>\n",
       "      <td>382.053171</td>\n",
       "      <td>56.022561</td>\n",
       "      <td>106.739813</td>\n",
       "      <td>73.627893</td>\n",
       "      <td>0.304415</td>\n",
       "      <td>3.950295</td>\n",
       "      <td>1.364356</td>\n",
       "      <td>1.580144</td>\n",
       "      <td>8.769083</td>\n",
       "      <td>4.727971</td>\n",
       "      <td>6217.223583</td>\n",
       "      <td>11169.275702</td>\n",
       "      <td>7955.735482</td>\n",
       "      <td>243.861391</td>\n",
       "      <td>387.62948</td>\n",
       "      <td>274.576920</td>\n",
       "      <td>668.486833</td>\n",
       "      <td>1095.034387</td>\n",
       "      <td>814.946722</td>\n",
       "      <td>14.347949</td>\n",
       "      <td>159651.816856</td>\n",
       "      <td>0.598231</td>\n",
       "      <td>0.701015</td>\n",
       "      <td>5.249856</td>\n",
       "      <td>16.491104</td>\n",
       "      <td>11.384207</td>\n",
       "      <td>26.084899</td>\n",
       "      <td>0.983842</td>\n",
       "      <td>2.789446</td>\n",
       "      <td>1.127602</td>\n",
       "      <td>11.774858</td>\n",
       "      <td>93.695502</td>\n",
       "      <td>30.375360</td>\n",
       "      <td>1.561302</td>\n",
       "      <td>141.095343</td>\n",
       "      <td>152.160327</td>\n",
       "      <td>198.847038</td>\n",
       "      <td>6.897665</td>\n",
       "      <td>2.372447</td>\n",
       "      <td>97.461089</td>\n",
       "      <td>32.101995</td>\n",
       "      <td>3.737502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.987000e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.640000e+04</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-122.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-83.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-83.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-193.000000</td>\n",
       "      <td>-83.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>-28.000000</td>\n",
       "      <td>-72.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-46.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-36.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-660.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.134635e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.027058e+06</td>\n",
       "      <td>43.321000</td>\n",
       "      <td>6019.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>67992.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>-360.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.282270e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.306528e+06</td>\n",
       "      <td>68.769000</td>\n",
       "      <td>9678.000000</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.875000</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>125800.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>-300.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.429904e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.124662e+07</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>14184.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>187.958328</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>107.949997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.924400</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.593498</td>\n",
       "      <td>20.897525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>151.380680</td>\n",
       "      <td>35.970001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>107.949997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>228749.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>-23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>-300.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>533.000000</td>\n",
       "      <td>486.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.577539e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.581113e+07</td>\n",
       "      <td>31937.391000</td>\n",
       "      <td>18396.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>10286.000000</td>\n",
       "      <td>11623.000000</td>\n",
       "      <td>4685.000000</td>\n",
       "      <td>5691.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2253.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>2253.000000</td>\n",
       "      <td>2255.000000</td>\n",
       "      <td>3331.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>3257.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "      <td>2918.000000</td>\n",
       "      <td>1429.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>819.000000</td>\n",
       "      <td>869.000000</td>\n",
       "      <td>819.000000</td>\n",
       "      <td>873.000000</td>\n",
       "      <td>843.000000</td>\n",
       "      <td>1707.791626</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>876.000000</td>\n",
       "      <td>670.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>880.000000</td>\n",
       "      <td>1410.00000</td>\n",
       "      <td>976.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>869.000000</td>\n",
       "      <td>1285.000000</td>\n",
       "      <td>928.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>93736.000000</td>\n",
       "      <td>133915.000000</td>\n",
       "      <td>98476.000000</td>\n",
       "      <td>90750.000000</td>\n",
       "      <td>90750.000000</td>\n",
       "      <td>90750.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>869.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3389.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>641511.437500</td>\n",
       "      <td>3300.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "      <td>93736.000000</td>\n",
       "      <td>98476.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>872.000000</td>\n",
       "      <td>964.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>861.000000</td>\n",
       "      <td>1235.000000</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>139777.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "      <td>8050.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "      <td>92888.000000</td>\n",
       "      <td>129006.000000</td>\n",
       "      <td>97628.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>153600.000000</td>\n",
       "      <td>153600.000000</td>\n",
       "      <td>153600.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>51200.000000</td>\n",
       "      <td>66000.000000</td>\n",
       "      <td>51200.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>880.000000</td>\n",
       "      <td>975.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>869.000000</td>\n",
       "      <td>1286.000000</td>\n",
       "      <td>928.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>108800.000000</td>\n",
       "      <td>145765.000000</td>\n",
       "      <td>108800.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>4817.470215</td>\n",
       "      <td>7519.870117</td>\n",
       "      <td>4817.470215</td>\n",
       "      <td>93736.000000</td>\n",
       "      <td>134021.000000</td>\n",
       "      <td>98476.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>880.000000</td>\n",
       "      <td>1411.000000</td>\n",
       "      <td>976.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>55125.00000</td>\n",
       "      <td>55125.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>104060.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>999595.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>854.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TransactionID        isFraud  TransactionDT  TransactionAmt  \\\n",
       "count   5.905400e+05  590540.000000   5.905400e+05   590540.000000   \n",
       "mean    3.282270e+06       0.034990   7.372311e+06      135.027176   \n",
       "std     1.704744e+05       0.183755   4.617224e+06      239.162522   \n",
       "min     2.987000e+06       0.000000   8.640000e+04        0.251000   \n",
       "25%     3.134635e+06       0.000000   3.027058e+06       43.321000   \n",
       "50%     3.282270e+06       0.000000   7.306528e+06       68.769000   \n",
       "75%     3.429904e+06       0.000000   1.124662e+07      125.000000   \n",
       "max     3.577539e+06       1.000000   1.581113e+07    31937.391000   \n",
       "\n",
       "               card1          card2          card3          card5  \\\n",
       "count  590540.000000  581607.000000  588975.000000  586281.000000   \n",
       "mean     9898.734658     362.555488     153.194925     199.278897   \n",
       "std      4901.170153     157.793246      11.336444      41.244453   \n",
       "min      1000.000000     100.000000     100.000000     100.000000   \n",
       "25%      6019.000000     214.000000     150.000000     166.000000   \n",
       "50%      9678.000000     361.000000     150.000000     226.000000   \n",
       "75%     14184.000000     512.000000     150.000000     226.000000   \n",
       "max     18396.000000     600.000000     231.000000     237.000000   \n",
       "\n",
       "               addr1          addr2          dist1         dist2  \\\n",
       "count  524834.000000  524834.000000  238269.000000  37627.000000   \n",
       "mean      290.733794      86.800630     118.502180    231.855423   \n",
       "std       101.741072       2.690623     371.872026    529.053494   \n",
       "min       100.000000      10.000000       0.000000      0.000000   \n",
       "25%       204.000000      87.000000       3.000000      7.000000   \n",
       "50%       299.000000      87.000000       8.000000     37.000000   \n",
       "75%       330.000000      87.000000      24.000000    206.000000   \n",
       "max       540.000000     102.000000   10286.000000  11623.000000   \n",
       "\n",
       "                  C1             C2             C3             C4  \\\n",
       "count  590540.000000  590540.000000  590540.000000  590540.000000   \n",
       "mean       14.092458      15.269734       0.005644       4.092185   \n",
       "std       133.569018     154.668899       0.150536      68.848459   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       0.000000       0.000000   \n",
       "50%         1.000000       1.000000       0.000000       0.000000   \n",
       "75%         3.000000       3.000000       0.000000       0.000000   \n",
       "max      4685.000000    5691.000000      26.000000    2253.000000   \n",
       "\n",
       "                  C5             C6             C7             C8  \\\n",
       "count  590540.000000  590540.000000  590540.000000  590540.000000   \n",
       "mean        5.571526       9.071082       2.848478       5.144574   \n",
       "std        25.786976      71.508467      61.727304      95.378574   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       1.000000       0.000000       0.000000   \n",
       "50%         0.000000       1.000000       0.000000       0.000000   \n",
       "75%         1.000000       2.000000       0.000000       0.000000   \n",
       "max       349.000000    2253.000000    2255.000000    3331.000000   \n",
       "\n",
       "                  C9            C10            C11            C12  \\\n",
       "count  590540.000000  590540.000000  590540.000000  590540.000000   \n",
       "mean        4.480240       5.240343      10.241521       4.076227   \n",
       "std        16.674897      95.581443      94.336292      86.666218   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000       0.000000   \n",
       "50%         1.000000       0.000000       1.000000       0.000000   \n",
       "75%         2.000000       0.000000       2.000000       0.000000   \n",
       "max       210.000000    3257.000000    3188.000000    3188.000000   \n",
       "\n",
       "                 C13            C14             D1             D2  \\\n",
       "count  590540.000000  590540.000000  589271.000000  309743.000000   \n",
       "mean       32.539918       8.295215      94.347568     169.563231   \n",
       "std       129.364844      49.544262     157.660387     177.315865   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       0.000000      26.000000   \n",
       "50%         3.000000       1.000000       3.000000      97.000000   \n",
       "75%        12.000000       2.000000     122.000000     276.000000   \n",
       "max      2918.000000    1429.000000     640.000000     640.000000   \n",
       "\n",
       "                  D3             D4             D5            D6  \\\n",
       "count  327662.000000  421618.000000  280699.000000  73187.000000   \n",
       "mean       28.343348     140.002441      42.335965     69.805717   \n",
       "std        62.384721     191.096774      89.000144    143.669253   \n",
       "min         0.000000    -122.000000       0.000000    -83.000000   \n",
       "25%         1.000000       0.000000       1.000000      0.000000   \n",
       "50%         8.000000      26.000000      10.000000      0.000000   \n",
       "75%        27.000000     253.000000      32.000000     40.000000   \n",
       "max       819.000000     869.000000     819.000000    873.000000   \n",
       "\n",
       "                 D7            D8            D9            D10            D11  \\\n",
       "count  38917.000000  74926.000000  74926.000000  514518.000000  311253.000000   \n",
       "mean      41.638950    146.058108      0.561057     123.982137     146.621465   \n",
       "std       99.743264    231.663840      0.316880     182.615225     186.042622   \n",
       "min        0.000000      0.000000      0.000000       0.000000     -53.000000   \n",
       "25%        0.000000      0.958333      0.208333       0.000000       0.000000   \n",
       "50%        0.000000     37.875000      0.666666      15.000000      43.000000   \n",
       "75%       17.000000    187.958328      0.833333     197.000000     274.000000   \n",
       "max      843.000000   1707.791626      0.958333     876.000000     670.000000   \n",
       "\n",
       "                D12           D13           D14            D15             V1  \\\n",
       "count  64717.000000  61952.000000  62187.000000  501427.000000  311253.000000   \n",
       "mean      54.037533     17.901295     57.724444     163.744579       0.999945   \n",
       "std      124.274558     67.614425    136.312450     202.726660       0.007390   \n",
       "min      -83.000000      0.000000   -193.000000     -83.000000       0.000000   \n",
       "25%        0.000000      0.000000      0.000000       0.000000       1.000000   \n",
       "50%        0.000000      0.000000      0.000000      52.000000       1.000000   \n",
       "75%       13.000000      0.000000      2.000000     314.000000       1.000000   \n",
       "max      648.000000    847.000000    878.000000     879.000000       1.000000   \n",
       "\n",
       "                  V2             V3             V4             V5  \\\n",
       "count  311253.000000  311253.000000  311253.000000  311253.000000   \n",
       "mean        1.045204       1.078075       0.846456       0.876991   \n",
       "std         0.240133       0.320890       0.440053       0.475902   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       1.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max         8.000000       9.000000       6.000000       6.000000   \n",
       "\n",
       "                  V6             V7             V8             V9  \\\n",
       "count  311253.000000  311253.000000  311253.000000  311253.000000   \n",
       "mean        1.045686       1.072870       1.027704       1.041529   \n",
       "std         0.239385       0.304779       0.186069       0.226339   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       1.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max         9.000000       9.000000       8.000000       8.000000   \n",
       "\n",
       "                 V10            V11            V12            V13  \\\n",
       "count  311253.000000  311253.000000  514467.000000  514467.000000   \n",
       "mean        0.463915       0.478987       0.559711       0.599166   \n",
       "std         0.521522       0.552431       0.510533       0.532185   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max         4.000000       5.000000       3.000000       6.000000   \n",
       "\n",
       "                 V14            V15            V16            V17  \\\n",
       "count  514467.000000  514467.000000  514467.000000  514467.000000   \n",
       "mean        0.999500       0.122342       0.123460       0.134040   \n",
       "std         0.022345       0.332422       0.342841       0.364456   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       0.000000       0.000000       0.000000   \n",
       "50%         1.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       7.000000      15.000000      15.000000   \n",
       "\n",
       "                 V18            V19            V20            V21  \\\n",
       "count  514467.000000  514467.000000  514467.000000  514467.000000   \n",
       "mean        0.135363       0.816371       0.847843       0.129684   \n",
       "std         0.371763       0.425512       0.459451       0.339060   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       1.000000       1.000000       0.000000   \n",
       "50%         0.000000       1.000000       1.000000       0.000000   \n",
       "75%         0.000000       1.000000       1.000000       0.000000   \n",
       "max        15.000000       7.000000      15.000000       5.000000   \n",
       "\n",
       "                 V22            V23            V24            V25  \\\n",
       "count  514467.000000  514467.000000  514467.000000  514467.000000   \n",
       "mean        0.132292       1.034791       1.058097       0.977660   \n",
       "std         0.359415       0.247681       0.305485       0.185245   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       1.000000       1.000000       1.000000   \n",
       "50%         0.000000       1.000000       1.000000       1.000000   \n",
       "75%         0.000000       1.000000       1.000000       1.000000   \n",
       "max         8.000000      13.000000      13.000000       7.000000   \n",
       "\n",
       "                 V26            V27            V28            V29  \\\n",
       "count  514467.000000  514467.000000  514467.000000  514467.000000   \n",
       "mean        0.988040       0.000776       0.000830       0.387840   \n",
       "std         0.209302       0.028596       0.031133       0.510652   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       0.000000       0.000000       0.000000   \n",
       "50%         1.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       0.000000       1.000000   \n",
       "max        13.000000       4.000000       4.000000       5.000000   \n",
       "\n",
       "                 V30            V31            V32            V33  \\\n",
       "count  514467.000000  514467.000000  514467.000000  514467.000000   \n",
       "mean        0.406436       0.140761       0.142417       0.130693   \n",
       "std         0.554311       0.355793       0.368278       0.340900   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       0.000000       0.000000   \n",
       "max         9.000000       7.000000      15.000000       7.000000   \n",
       "\n",
       "                 V34            V35            V36            V37  \\\n",
       "count  514467.000000  421571.000000  421571.000000  421571.000000   \n",
       "mean        0.139154       0.542594       0.579198       1.108065   \n",
       "std         0.357549       0.516010       0.539039       0.690571   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       1.000000   \n",
       "50%         0.000000       1.000000       1.000000       1.000000   \n",
       "75%         0.000000       1.000000       1.000000       1.000000   \n",
       "max        13.000000       3.000000       5.000000      54.000000   \n",
       "\n",
       "                V38            V39            V40            V41  \\\n",
       "count  421571.00000  421571.000000  421571.000000  421571.000000   \n",
       "mean        1.16240       0.166076       0.177145       0.999269   \n",
       "std         0.85892       0.451956       0.505786       0.027020   \n",
       "min         0.00000       0.000000       0.000000       0.000000   \n",
       "25%         1.00000       0.000000       0.000000       1.000000   \n",
       "50%         1.00000       0.000000       0.000000       1.000000   \n",
       "75%         1.00000       0.000000       0.000000       1.000000   \n",
       "max        54.00000      15.000000      24.000000       1.000000   \n",
       "\n",
       "                 V42            V43            V44            V45  \\\n",
       "count  421571.000000  421571.000000  421571.000000  421571.000000   \n",
       "mean        0.156118       0.168942       1.083891       1.120779   \n",
       "std         0.382896       0.433359       0.639143       0.729774   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000       1.000000   \n",
       "50%         0.000000       0.000000       1.000000       1.000000   \n",
       "75%         0.000000       0.000000       1.000000       1.000000   \n",
       "max         8.000000       8.000000      48.000000      48.000000   \n",
       "\n",
       "                 V46            V47            V48            V49  \\\n",
       "count  421571.000000  421571.000000  421571.000000  421571.000000   \n",
       "mean        1.022286       1.038515       0.383174       0.397724   \n",
       "std         0.166719       0.231862       0.508189       0.542654   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       0.000000       0.000000   \n",
       "50%         1.000000       1.000000       0.000000       0.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max         6.000000      12.000000       5.000000       5.000000   \n",
       "\n",
       "                 V50            V51            V52            V53  \\\n",
       "count  421571.000000  421571.000000  421571.000000  513444.000000   \n",
       "mean        0.164746       0.170579       0.182695       0.577586   \n",
       "std         0.373995       0.403899       0.439002       0.511571   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       1.000000   \n",
       "75%         0.000000       0.000000       0.000000       1.000000   \n",
       "max         5.000000       6.000000      12.000000       5.000000   \n",
       "\n",
       "                 V54            V55            V56            V57  \\\n",
       "count  513444.000000  513444.000000  513444.000000  513444.000000   \n",
       "mean        0.619982       1.067670       1.120979       0.128312   \n",
       "std         0.534635       0.391364       0.661129       0.349094   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       1.000000       1.000000       0.000000   \n",
       "50%         1.000000       1.000000       1.000000       0.000000   \n",
       "75%         1.000000       1.000000       1.000000       0.000000   \n",
       "max         6.000000      17.000000      51.000000       6.000000   \n",
       "\n",
       "                 V58            V59            V60            V61  \\\n",
       "count  513444.000000  513444.000000  513444.000000  513444.000000   \n",
       "mean        0.132453       0.134433       0.142537       0.829785   \n",
       "std         0.372907       0.379291       0.418230       0.436617   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       1.000000   \n",
       "50%         0.000000       0.000000       0.000000       1.000000   \n",
       "75%         0.000000       0.000000       0.000000       1.000000   \n",
       "max        10.000000      16.000000      16.000000       6.000000   \n",
       "\n",
       "                 V62            V63            V64            V65  \\\n",
       "count  513444.000000  513444.000000  513444.000000  513444.000000   \n",
       "mean        0.867563       0.130743       0.141825       0.999663   \n",
       "std         0.483803       0.355262       0.406157       0.018353   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       0.000000       0.000000       1.000000   \n",
       "50%         1.000000       0.000000       0.000000       1.000000   \n",
       "75%         1.000000       0.000000       0.000000       1.000000   \n",
       "max        10.000000       7.000000       7.000000       1.000000   \n",
       "\n",
       "                 V66            V67            V68            V69  \\\n",
       "count  513444.000000  513444.000000  513444.000000  513444.000000   \n",
       "mean        0.981038       0.998121       0.000534       0.390200   \n",
       "std         0.216235       0.245912       0.023760       0.513696   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       0.000000       0.000000   \n",
       "50%         1.000000       1.000000       0.000000       0.000000   \n",
       "75%         1.000000       1.000000       0.000000       1.000000   \n",
       "max         7.000000       8.000000       2.000000       5.000000   \n",
       "\n",
       "                 V70            V71            V72            V73  \\\n",
       "count  513444.000000  513444.000000  513444.000000  513444.000000   \n",
       "mean        0.407924       0.140639       0.145124       0.139982   \n",
       "std         0.554499       0.364303       0.389212       0.367098   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       0.000000       0.000000   \n",
       "max         6.000000       6.000000      10.000000       7.000000   \n",
       "\n",
       "                 V74            V75            V76            V77  \\\n",
       "count  513444.000000  501376.000000  501376.000000  501376.000000   \n",
       "mean        0.152147       0.544278       0.587557       1.086893   \n",
       "std         0.393274       0.514318       0.538230       0.532958   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       1.000000   \n",
       "50%         0.000000       1.000000       1.000000       1.000000   \n",
       "75%         0.000000       1.000000       1.000000       1.000000   \n",
       "max         8.000000       4.000000       6.000000      30.000000   \n",
       "\n",
       "                 V78            V79            V80            V81  \\\n",
       "count  501376.000000  501376.000000  501376.000000  501376.000000   \n",
       "mean        1.144462       0.136867       0.143954       0.152696   \n",
       "std         0.781474       0.379904       0.409932       0.452298   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       0.000000       0.000000       0.000000   \n",
       "50%         1.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       0.000000       0.000000   \n",
       "max        31.000000       7.000000      19.000000      19.000000   \n",
       "\n",
       "                 V82            V83            V84            V85  \\\n",
       "count  501376.000000  501376.000000  501376.000000  501376.000000   \n",
       "mean        0.844610       0.881965       0.137145       0.149788   \n",
       "std         0.422529       0.470757       0.361875       0.419445   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       0.000000       0.000000   \n",
       "50%         1.000000       1.000000       0.000000       0.000000   \n",
       "75%         1.000000       1.000000       0.000000       0.000000   \n",
       "max         7.000000       7.000000       7.000000       7.000000   \n",
       "\n",
       "                 V86            V87            V88            V89  \\\n",
       "count  501376.000000  501376.000000  501376.000000  501376.000000   \n",
       "mean        1.064885       1.099456       0.999246       0.000902   \n",
       "std         0.419807       0.511281       0.027447       0.031943   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       0.000000   \n",
       "50%         1.000000       1.000000       1.000000       0.000000   \n",
       "75%         1.000000       1.000000       1.000000       0.000000   \n",
       "max        30.000000      30.000000       1.000000       2.000000   \n",
       "\n",
       "                 V90            V91            V92            V93  \\\n",
       "count  501376.000000  501376.000000  501376.000000  501376.000000   \n",
       "mean        0.401862       0.420461       0.150322       0.154812   \n",
       "std         0.516153       0.561865       0.375682       0.402314   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       1.000000       0.000000       0.000000   \n",
       "max         5.000000       6.000000       7.000000       7.000000   \n",
       "\n",
       "                 V94            V95           V96            V97  \\\n",
       "count  501376.000000  590226.000000  590226.00000  590226.000000   \n",
       "mean        0.137007       1.038019       3.00519       1.718933   \n",
       "std         0.343878      21.034304      40.23949      27.700449   \n",
       "min         0.000000       0.000000       0.00000       0.000000   \n",
       "25%         0.000000       0.000000       0.00000       0.000000   \n",
       "50%         0.000000       0.000000       0.00000       0.000000   \n",
       "75%         0.000000       0.000000       1.00000       0.000000   \n",
       "max         2.000000     880.000000    1410.00000     976.000000   \n",
       "\n",
       "                 V98            V99           V100           V101  \\\n",
       "count  590226.000000  590226.000000  590226.000000  590226.000000   \n",
       "mean        0.061985       0.894986       0.273504       0.889249   \n",
       "std         0.284995       2.722552       0.947176      20.582571   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       1.000000       0.000000       0.000000   \n",
       "max        12.000000      88.000000      28.000000     869.000000   \n",
       "\n",
       "                V102           V103           V104           V105  \\\n",
       "count  590226.000000  590226.000000  590226.000000  590226.000000   \n",
       "mean        1.827229       1.279288       0.085433       0.281145   \n",
       "std        35.928456      25.685642       0.648718       3.373948   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max      1285.000000     928.000000      15.000000      99.000000   \n",
       "\n",
       "                V106           V107           V108           V109  \\\n",
       "count  590226.000000  590226.000000  590226.000000  590226.000000   \n",
       "mean        0.164584       0.999580       1.004613       1.014816   \n",
       "std         1.825665       0.020494       0.081146       0.127769   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       1.000000       1.000000       1.000000   \n",
       "50%         0.000000       1.000000       1.000000       1.000000   \n",
       "75%         0.000000       1.000000       1.000000       1.000000   \n",
       "max        55.000000       1.000000       7.000000       7.000000   \n",
       "\n",
       "                V110           V111           V112           V113  \\\n",
       "count  590226.000000  590226.000000  590226.000000  590226.000000   \n",
       "mean        1.007739       1.002563       1.005356       1.003383   \n",
       "std         0.097290       0.070830       0.084617       0.074754   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       1.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max         7.000000       9.000000       9.000000       9.000000   \n",
       "\n",
       "                V114           V115           V116           V117  \\\n",
       "count  590226.000000  590226.000000  590226.000000  590226.000000   \n",
       "mean        1.009298       1.032450       1.015738       1.000391   \n",
       "std         0.110179       0.190385       0.136770       0.035238   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       1.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max         6.000000       6.000000       6.000000       3.000000   \n",
       "\n",
       "                V118           V119           V120           V121  \\\n",
       "count  590226.000000  590226.000000  590226.000000  590226.000000   \n",
       "mean        1.001474       1.000729       1.000874       1.004276   \n",
       "std         0.041011       0.036392       0.041684       0.067097   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       1.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max         3.000000       3.000000       3.000000       3.000000   \n",
       "\n",
       "                V122           V123           V124           V125  \\\n",
       "count  590226.000000  590226.000000  590226.000000  590226.000000   \n",
       "mean        1.001759       1.031120       1.092975       1.050415   \n",
       "std         0.048636       0.228134       0.374103       0.280037   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       1.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max         3.000000      13.000000      13.000000      13.000000   \n",
       "\n",
       "                V126           V127           V128           V129  \\\n",
       "count  590226.000000  590226.000000  590226.000000  590226.000000   \n",
       "mean      129.979417     336.611559     204.094038       8.768944   \n",
       "std      2346.951681    4238.666949    3010.258774     113.832828   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000     107.949997       0.000000       0.000000   \n",
       "max    160000.000000  160000.000000  160000.000000   55125.000000   \n",
       "\n",
       "                V130           V131           V132           V133  \\\n",
       "count  590226.000000  590226.000000  590226.000000  590226.000000   \n",
       "mean       92.165849      31.133302     103.513188     204.889160   \n",
       "std       315.960485     161.161258    2266.106140    3796.316755   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%        59.000000       0.000000       0.000000       0.000000   \n",
       "max     55125.000000   55125.000000   93736.000000  133915.000000   \n",
       "\n",
       "                V134           V135           V136           V137  \\\n",
       "count  590226.000000  590226.000000  590226.000000  590226.000000   \n",
       "mean      145.972328      17.250132      38.821196      26.365090   \n",
       "std      2772.986817     293.847563     451.808411     348.332714   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max     98476.000000   90750.000000   90750.000000   90750.000000   \n",
       "\n",
       "               V138          V139          V140          V141          V142  \\\n",
       "count  81945.000000  81945.000000  81945.000000  81945.000000  81945.000000   \n",
       "mean       0.036439      1.073915      1.125267      0.037696      0.048581   \n",
       "std        0.428490      1.333924      1.467850      0.215133      0.313888   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "75%        0.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "max       22.000000     33.000000     33.000000      5.000000      9.000000   \n",
       "\n",
       "               V143          V144          V145          V146          V147  \\\n",
       "count  81951.000000  81951.000000  81951.000000  81945.000000  81945.000000   \n",
       "mean       8.397006      3.708484     22.112946      0.156276      0.168601   \n",
       "std       55.267545     10.485633     64.371860      0.682328      0.750497   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "max      869.000000     62.000000    297.000000     24.000000     26.000000   \n",
       "\n",
       "               V148          V149          V150          V151          V152  \\\n",
       "count  81945.000000  81945.000000  81951.000000  81951.000000  81951.000000   \n",
       "mean       0.765001      0.775313    277.598028      6.460190      9.432710   \n",
       "std        0.581425      0.628191    829.576922     15.232324     21.554486   \n",
       "min        0.000000      0.000000      1.000000      1.000000      1.000000   \n",
       "25%        0.000000      0.000000      1.000000      1.000000      1.000000   \n",
       "50%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "75%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "max       20.000000     20.000000   3389.000000     57.000000     69.000000   \n",
       "\n",
       "               V153          V154          V155          V156          V157  \\\n",
       "count  81945.000000  81945.000000  81945.000000  81945.000000  81945.000000   \n",
       "mean       0.753200      0.757423      0.767381      0.777485      0.817573   \n",
       "std        0.532649      0.546907      0.602678      0.647209      0.682016   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "75%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "max       18.000000     18.000000     24.000000     24.000000     24.000000   \n",
       "\n",
       "               V158          V159           V160          V161          V162  \\\n",
       "count  81945.000000  81951.000000   81951.000000  81945.000000  81945.000000   \n",
       "mean       0.833461   2719.299775   47453.181173      4.843938      6.594661   \n",
       "std        0.734336   8355.445049  142076.069162     58.929757     69.195180   \n",
       "min        0.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "max       24.000000  55125.000000  641511.437500   3300.000000   3300.000000   \n",
       "\n",
       "               V163          V164          V165           V166           V167  \\\n",
       "count  81945.000000  81951.000000  81951.000000   81951.000000  139631.000000   \n",
       "mean       5.505955    877.888928   2239.912219     359.469437       3.929514   \n",
       "std       63.077887   6049.166505   8223.258928    1244.463270      42.200980   \n",
       "min        0.000000      0.000000      0.000000       0.000000       0.000000   \n",
       "25%        0.000000      0.000000      0.000000       0.000000       0.000000   \n",
       "50%        0.000000      0.000000      0.000000       0.000000       0.000000   \n",
       "75%        0.000000      0.000000      0.000000       0.000000       0.000000   \n",
       "max     3300.000000  93736.000000  98476.000000  104060.000000     872.000000   \n",
       "\n",
       "                V168           V169           V170           V171  \\\n",
       "count  139631.000000  139819.000000  139819.000000  139819.000000   \n",
       "mean        5.859501       0.168053       1.436779       1.690908   \n",
       "std        54.032468       0.904944       1.751143       2.444748   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000       1.000000   \n",
       "50%         0.000000       0.000000       1.000000       1.000000   \n",
       "75%         1.000000       0.000000       1.000000       1.000000   \n",
       "max       964.000000      19.000000      48.000000      61.000000   \n",
       "\n",
       "                V172           V173           V174           V175  \\\n",
       "count  139631.000000  139631.000000  139819.000000  139819.000000   \n",
       "mean        0.132012       0.055231       0.127794       0.212639   \n",
       "std         0.924894       0.264439       0.379763       0.857133   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max        31.000000       7.000000       8.000000      14.000000   \n",
       "\n",
       "                V176           V177           V178           V179  \\\n",
       "count  139631.000000  139631.000000  139631.000000  139631.000000   \n",
       "mean        1.376979       3.529245       6.649283       4.869012   \n",
       "std         1.829420      41.310622      69.447364      50.489426   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       0.000000       0.000000       0.000000   \n",
       "50%         1.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       0.000000       0.000000   \n",
       "max        48.000000     861.000000    1235.000000     920.000000   \n",
       "\n",
       "                V180           V181           V182           V183  \\\n",
       "count  139819.000000  139631.000000  139631.000000  139631.000000   \n",
       "mean        0.924123       0.253332       0.856243       0.484692   \n",
       "std         6.112630       1.248974       5.792934       2.946982   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max        83.000000      24.000000      83.000000      41.000000   \n",
       "\n",
       "                V184           V185           V186           V187  \\\n",
       "count  139819.000000  139819.000000  139631.000000  139631.000000   \n",
       "mean        0.132364       0.173903       1.148799       1.843752   \n",
       "std         0.543699       0.699733       1.223529       9.884390   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000       1.000000   \n",
       "50%         0.000000       0.000000       1.000000       1.000000   \n",
       "75%         0.000000       0.000000       1.000000       1.000000   \n",
       "max        16.000000      31.000000      38.000000     218.000000   \n",
       "\n",
       "                V188           V189           V190           V191  \\\n",
       "count  139819.000000  139819.000000  139631.000000  139631.000000   \n",
       "mean        1.014755       1.038314       1.213083       1.058984   \n",
       "std         0.671207       0.792528       1.480318       0.677527   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       1.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max        30.000000      30.000000      42.000000      21.000000   \n",
       "\n",
       "                V192           V193           V194           V195  \\\n",
       "count  139631.000000  139631.000000  139819.000000  139819.000000   \n",
       "mean        1.237361       1.149845       0.945773       0.954227   \n",
       "std         2.635961       1.714792       0.304158       0.376420   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       1.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max        44.000000      37.000000       7.000000      16.000000   \n",
       "\n",
       "                V196           V197           V198           V199  \\\n",
       "count  139631.000000  139819.000000  139819.000000  139631.000000   \n",
       "mean        1.084580       0.949385       0.961951       1.270749   \n",
       "std         1.105834       0.336871       0.493065       1.671863   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       1.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max        38.000000      14.000000      21.000000      45.000000   \n",
       "\n",
       "                V200           V201           V202           V203  \\\n",
       "count  139819.000000  139819.000000  139631.000000  139631.000000   \n",
       "mean        1.119977       1.159106     444.147142    1078.327538   \n",
       "std         1.253853       1.418618    4683.828419    9105.607991   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       0.000000       0.000000   \n",
       "50%         1.000000       1.000000       0.000000       0.000000   \n",
       "75%         1.000000       1.000000       0.000000      30.924400   \n",
       "max        45.000000      55.000000  104060.000000  139777.000000   \n",
       "\n",
       "                V204           V205           V206           V207  \\\n",
       "count  139631.000000  139631.000000  139631.000000  139631.000000   \n",
       "mean      686.956931      18.060417       6.189360      72.284098   \n",
       "std      6048.980716     266.545451     191.474014     925.676660   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%        20.000000       0.000000       0.000000       0.000000   \n",
       "max    104060.000000   55125.000000   55125.000000   55125.000000   \n",
       "\n",
       "                V208           V209           V210           V211  \\\n",
       "count  139819.000000  139819.000000  139819.000000  139631.000000   \n",
       "mean        8.888193      35.001872      14.391835     385.137037   \n",
       "std        59.047125     250.800822      86.523724    4541.837915   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max      3300.000000    8050.000000    3300.000000   92888.000000   \n",
       "\n",
       "                V212           V213           V214           V215  \\\n",
       "count  139631.000000  139631.000000  139631.000000  139631.000000   \n",
       "mean      765.988339     536.302802      38.437547     133.208217   \n",
       "std      7496.120737    5471.664736     571.834283    1040.453748   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max    129006.000000   97628.000000  104060.000000  104060.000000   \n",
       "\n",
       "                V216           V217           V218           V219  \\\n",
       "count  139631.000000  130430.000000  130430.000000  130430.000000   \n",
       "mean       71.107143       1.054619       1.725784       1.367132   \n",
       "std       680.267625       9.547354      13.919876      12.044032   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       1.000000       1.000000   \n",
       "max    104060.000000     303.000000     400.000000     378.000000   \n",
       "\n",
       "                V220           V221           V222           V223  \\\n",
       "count  141416.000000  141416.000000  141416.000000  130430.000000   \n",
       "mean        0.169472       1.274912       1.359005       0.093153   \n",
       "std         1.002463       2.728792       2.913772       0.402232   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       1.000000       1.000000       0.000000   \n",
       "50%         0.000000       1.000000       1.000000       0.000000   \n",
       "75%         0.000000       1.000000       1.000000       0.000000   \n",
       "max        25.000000     384.000000     384.000000      16.000000   \n",
       "\n",
       "                V224           V225           V226           V227  \\\n",
       "count  130430.000000  130430.000000  130430.000000  141416.000000   \n",
       "mean        0.394748       0.191758       0.247612       0.147975   \n",
       "std         3.443310       1.290820       2.756449       2.049363   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max       144.000000      51.000000     242.000000     360.000000   \n",
       "\n",
       "                V228           V229           V230           V231  \\\n",
       "count  130430.000000  130430.000000  130430.000000  130430.000000   \n",
       "mean        1.351928       1.638710       1.465476       0.765506   \n",
       "std         1.409722       4.316026       2.122783       8.877119   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       0.000000   \n",
       "50%         1.000000       1.000000       1.000000       0.000000   \n",
       "75%         1.000000       1.000000       1.000000       0.000000   \n",
       "max        54.000000     176.000000      65.000000     293.000000   \n",
       "\n",
       "                V232           V233           V234           V235  \\\n",
       "count  130430.000000  130430.000000  141416.000000  130430.000000   \n",
       "mean        1.005597       0.908388       2.092847       0.184106   \n",
       "std        10.460253      10.149884      11.323036       0.902639   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max       337.000000     332.000000     121.000000      23.000000   \n",
       "\n",
       "                V236           V237           V238           V239  \\\n",
       "count  130430.000000  130430.000000  141416.000000  141416.000000   \n",
       "mean        0.307667       0.253500       0.127956       0.136965   \n",
       "std         2.152332       1.716634       0.574657       0.616260   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max        45.000000      39.000000      23.000000      23.000000   \n",
       "\n",
       "                V240           V241           V242           V243  \\\n",
       "count  130430.000000  130430.000000  130430.000000  130430.000000   \n",
       "mean        1.000997       1.000238       1.113463       1.178387   \n",
       "std         0.049522       0.022663       0.660110       1.398953   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       1.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max         7.000000       5.000000      20.000000      57.000000   \n",
       "\n",
       "                V244           V245           V246           V247  \\\n",
       "count  130430.000000  141416.000000  130430.000000  130430.000000   \n",
       "mean        1.118562       0.876619       1.183723       1.025355   \n",
       "std         0.698807       1.821065       1.040363       0.281604   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       1.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max        22.000000     262.000000      45.000000      18.000000   \n",
       "\n",
       "                V248           V249           V250           V251  \\\n",
       "count  130430.000000  130430.000000  141416.000000  141416.000000   \n",
       "mean        1.069493       1.042851       0.788588       0.794231   \n",
       "std         0.888341       0.528812       0.488386       0.501240   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       1.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max        36.000000      22.000000      18.000000      18.000000   \n",
       "\n",
       "                V252           V253           V254           V255  \\\n",
       "count  130430.000000  130430.000000  130430.000000  141416.000000   \n",
       "mean        1.032048       1.162164       1.075113       0.806656   \n",
       "std         0.389546       3.612553       1.357550       0.939124   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       1.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max        24.000000     163.000000      60.000000      87.000000   \n",
       "\n",
       "                V256           V257           V258           V259  \\\n",
       "count  141416.000000  130430.000000  130430.000000  141416.000000   \n",
       "mean        0.814950       1.250993       1.343510       0.967832   \n",
       "std         0.969953       1.299956       2.015811       2.113447   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       1.000000   \n",
       "50%         1.000000       1.000000       1.000000       1.000000   \n",
       "75%         1.000000       1.000000       1.000000       1.000000   \n",
       "max        87.000000      48.000000      66.000000     285.000000   \n",
       "\n",
       "                V260           V261           V262           V263  \\\n",
       "count  130430.000000  130430.000000  130430.000000  130430.000000   \n",
       "mean        0.964425       1.107161       1.013279     117.390676   \n",
       "std         0.379828       1.323230       0.625455    1294.851543   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       0.000000   \n",
       "50%         1.000000       1.000000       1.000000       0.000000   \n",
       "75%         1.000000       1.000000       1.000000       0.000000   \n",
       "max         8.000000      49.000000      20.000000  153600.000000   \n",
       "\n",
       "                V264           V265           V266           V267  \\\n",
       "count  130430.000000  130430.000000  130430.000000  130430.000000   \n",
       "mean      201.657617     153.520534       9.167839      36.525103   \n",
       "std      2284.827492    1605.512276     208.038863     644.878586   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%        33.593498      20.897525       0.000000       0.000000   \n",
       "max    153600.000000  153600.000000   55125.000000   55125.000000   \n",
       "\n",
       "                V268           V269           V270           V271  \\\n",
       "count  130430.000000  130430.000000  141416.000000  141416.000000   \n",
       "mean       18.813407       5.997508       7.712764       9.445133   \n",
       "std       311.280181     207.317539      65.507232      74.147726   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max     55125.000000   55125.000000    4000.000000    4000.000000   \n",
       "\n",
       "                V272           V273           V274           V275  \\\n",
       "count  141416.000000  130430.000000  130430.000000  130430.000000   \n",
       "mean        8.464571      73.825549     107.151636      88.899939   \n",
       "std        69.723735     935.187927    1258.734139    1072.883139   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max      4000.000000   51200.000000   66000.000000   51200.000000   \n",
       "\n",
       "                V276           V277           V278           V279  \\\n",
       "count  130430.000000  130430.000000  130430.000000  590528.000000   \n",
       "mean       31.797277      51.956645      42.328228       1.123061   \n",
       "std       615.659714     732.145368     660.611820      21.021950   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max    104060.000000  104060.000000  104060.000000     880.000000   \n",
       "\n",
       "                V280           V281           V282           V283  \\\n",
       "count  590528.000000  589271.000000  589271.000000  589271.000000   \n",
       "mean        1.967082       0.087783       0.817171       0.991114   \n",
       "std        27.851780       0.512748       0.921880       1.558731   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       1.000000       1.000000   \n",
       "75%         1.000000       0.000000       1.000000       1.000000   \n",
       "max       975.000000      22.000000      32.000000      68.000000   \n",
       "\n",
       "                V284           V285           V286           V287  \\\n",
       "count  590528.000000  590528.000000  590528.000000  590528.000000   \n",
       "mean        0.088543       1.167660       0.031492       0.358579   \n",
       "std         0.338424       3.282454       0.190939       1.078995   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       1.000000       0.000000       0.000000   \n",
       "max        12.000000      95.000000       8.000000      31.000000   \n",
       "\n",
       "                V288           V289           V290           V291  \\\n",
       "count  589271.000000  589271.000000  590528.000000  590528.000000   \n",
       "mean        0.184350       0.235975       1.103011       1.659811   \n",
       "std         0.430989       0.599231       0.768897      16.252538   \n",
       "min         0.000000       0.000000       1.000000       1.000000   \n",
       "25%         0.000000       0.000000       1.000000       1.000000   \n",
       "50%         0.000000       0.000000       1.000000       1.000000   \n",
       "75%         0.000000       0.000000       1.000000       1.000000   \n",
       "max        10.000000      12.000000      67.000000    1055.000000   \n",
       "\n",
       "                V292           V293           V294           V295  \\\n",
       "count  590528.000000  590528.000000  590528.000000  590528.000000   \n",
       "mean        1.239916       0.942599       2.313863       1.433424   \n",
       "std         3.775050      20.588816      39.526468      25.962948   \n",
       "min         1.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       0.000000       0.000000       0.000000   \n",
       "50%         1.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       0.000000       0.000000   \n",
       "max       323.000000     869.000000    1286.000000     928.000000   \n",
       "\n",
       "                V296           V297           V298           V299  \\\n",
       "count  589271.000000  590528.000000  590528.000000  590528.000000   \n",
       "mean        0.328917       0.089034       0.298829       0.171655   \n",
       "std         3.264745       0.628352       3.175062       1.724218   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max        93.000000      12.000000      93.000000      49.000000   \n",
       "\n",
       "                V300           V301           V302           V303  \\\n",
       "count  589271.000000  589271.000000  590528.000000  590528.000000   \n",
       "mean        0.045507       0.052002       0.251761       0.283140   \n",
       "std         0.289573       0.318310       0.481889       0.623608   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max        11.000000      13.000000      16.000000      20.000000   \n",
       "\n",
       "                V304           V305           V306           V307  \\\n",
       "count  590528.000000  590528.000000  590528.000000  590528.000000   \n",
       "mean        0.264208       1.000007     139.748713     408.682375   \n",
       "std         0.528238       0.002603    2348.849634    4391.992977   \n",
       "min         0.000000       1.000000       0.000000       0.000000   \n",
       "25%         0.000000       1.000000       0.000000       0.000000   \n",
       "50%         0.000000       1.000000       0.000000       0.000000   \n",
       "75%         0.000000       1.000000       0.000000     151.380680   \n",
       "max        16.000000       2.000000  108800.000000  145765.000000   \n",
       "\n",
       "                V308           V309           V310           V311  \\\n",
       "count  590528.000000  590528.000000  590528.000000  590528.000000   \n",
       "mean      230.413180      10.995986     118.195658       4.202175   \n",
       "std      3021.924247     116.254277     352.983093     102.374938   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%        35.970001       0.000000     107.949997       0.000000   \n",
       "max    108800.000000   55125.000000   55125.000000   55125.000000   \n",
       "\n",
       "                V312           V313           V314           V315  \\\n",
       "count  590528.000000  589271.000000  589271.000000  589271.000000   \n",
       "mean       39.173910      21.351473      43.319174      26.806977   \n",
       "std       172.128339      95.902970     173.619028     116.853222   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max     55125.000000    4817.470215    7519.870117    4817.470215   \n",
       "\n",
       "                V316           V317           V318           V319  \\\n",
       "count  590528.000000  590528.000000  590528.000000  590528.000000   \n",
       "mean      109.818544     247.606741     162.153398      18.372476   \n",
       "std      2270.033202    3980.042828    2793.343636     332.304848   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max     93736.000000  134021.000000   98476.000000  104060.000000   \n",
       "\n",
       "                V320           V321          V322          V323          V324  \\\n",
       "count  590528.000000  590528.000000  82351.000000  82351.000000  82351.000000   \n",
       "mean       42.073133      28.326584      6.220289     13.103775      9.184612   \n",
       "std       473.499307     382.053171     56.022561    106.739813     73.627893   \n",
       "min         0.000000       0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000       0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000       0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000       0.000000      0.000000      1.000000      0.000000   \n",
       "max    104060.000000  104060.000000    880.000000   1411.000000    976.000000   \n",
       "\n",
       "               V325          V326          V327          V328          V329  \\\n",
       "count  82351.000000  82351.000000  82351.000000  82351.000000  82351.000000   \n",
       "mean       0.058494      0.851040      0.296633      0.336790      1.312844   \n",
       "std        0.304415      3.950295      1.364356      1.580144      8.769083   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       12.000000     44.000000     18.000000     15.000000     99.000000   \n",
       "\n",
       "               V330           V331           V332           V333  \\\n",
       "count  82351.000000   82351.000000   82351.000000   82351.000000   \n",
       "mean       0.775874     721.741883    1375.783644    1014.622782   \n",
       "std        4.727971    6217.223583   11169.275702    7955.735482   \n",
       "min        0.000000       0.000000       0.000000       0.000000   \n",
       "25%        0.000000       0.000000       0.000000       0.000000   \n",
       "50%        0.000000       0.000000       0.000000       0.000000   \n",
       "75%        0.000000       0.000000      25.000000       0.000000   \n",
       "max       55.000000  160000.000000  160000.000000  160000.000000   \n",
       "\n",
       "               V334         V335          V336           V337           V338  \\\n",
       "count  82351.000000  82351.00000  82351.000000   82351.000000   82351.000000   \n",
       "mean       9.807015     59.16455     28.530903      55.352422     151.160542   \n",
       "std      243.861391    387.62948    274.576920     668.486833    1095.034387   \n",
       "min        0.000000      0.00000      0.000000       0.000000       0.000000   \n",
       "25%        0.000000      0.00000      0.000000       0.000000       0.000000   \n",
       "50%        0.000000      0.00000      0.000000       0.000000       0.000000   \n",
       "75%        0.000000      0.00000      0.000000       0.000000       0.000000   \n",
       "max    55125.000000  55125.00000  55125.000000  104060.000000  104060.000000   \n",
       "\n",
       "                V339          id_01          id_02         id_03  \\\n",
       "count   82351.000000  144233.000000  140872.000000  66324.000000   \n",
       "mean      100.700882     -10.170502  174716.584708      0.060189   \n",
       "std       814.946722      14.347949  159651.816856      0.598231   \n",
       "min         0.000000    -100.000000       1.000000    -13.000000   \n",
       "25%         0.000000     -10.000000   67992.000000      0.000000   \n",
       "50%         0.000000      -5.000000  125800.500000      0.000000   \n",
       "75%         0.000000      -5.000000  228749.000000      0.000000   \n",
       "max    104060.000000       0.000000  999595.000000     10.000000   \n",
       "\n",
       "              id_04          id_05          id_06        id_07        id_08  \\\n",
       "count  66324.000000  136865.000000  136865.000000  5155.000000  5155.000000   \n",
       "mean      -0.058938       1.615585      -6.698710    13.285354   -38.600388   \n",
       "std        0.701015       5.249856      16.491104    11.384207    26.084899   \n",
       "min      -28.000000     -72.000000    -100.000000   -46.000000  -100.000000   \n",
       "25%        0.000000       0.000000      -6.000000     5.000000   -48.000000   \n",
       "50%        0.000000       0.000000       0.000000    14.000000   -34.000000   \n",
       "75%        0.000000       1.000000       0.000000    22.000000   -23.000000   \n",
       "max        0.000000      52.000000       0.000000    61.000000     0.000000   \n",
       "\n",
       "              id_09         id_10          id_11          id_13         id_14  \\\n",
       "count  74926.000000  74926.000000  140978.000000  127320.000000  80044.000000   \n",
       "mean       0.091023     -0.301124      99.745325      48.053071   -344.507146   \n",
       "std        0.983842      2.789446       1.127602      11.774858     93.695502   \n",
       "min      -36.000000   -100.000000      90.000000      10.000000   -660.000000   \n",
       "25%        0.000000      0.000000     100.000000      49.000000   -360.000000   \n",
       "50%        0.000000      0.000000     100.000000      52.000000   -300.000000   \n",
       "75%        0.000000      0.000000     100.000000      52.000000   -300.000000   \n",
       "max       25.000000      0.000000     100.000000      64.000000    720.000000   \n",
       "\n",
       "               id_17         id_18          id_19          id_20        id_21  \\\n",
       "count  139369.000000  45113.000000  139318.000000  139261.000000  5159.000000   \n",
       "mean      189.451377     14.237337     353.128174     403.882666   368.269820   \n",
       "std        30.375360      1.561302     141.095343     152.160327   198.847038   \n",
       "min       100.000000     10.000000     100.000000     100.000000   100.000000   \n",
       "25%       166.000000     13.000000     266.000000     256.000000   252.000000   \n",
       "50%       166.000000     15.000000     341.000000     472.000000   252.000000   \n",
       "75%       225.000000     15.000000     427.000000     533.000000   486.500000   \n",
       "max       229.000000     29.000000     671.000000     661.000000   854.000000   \n",
       "\n",
       "             id_22        id_24        id_25        id_26         id_32  \n",
       "count  5169.000000  4747.000000  5132.000000  5163.000000  77586.000000  \n",
       "mean     16.002708    12.800927   329.608924   149.070308     26.508597  \n",
       "std       6.897665     2.372447    97.461089    32.101995      3.737502  \n",
       "min      10.000000    11.000000   100.000000   100.000000      0.000000  \n",
       "25%      14.000000    11.000000   321.000000   119.000000     24.000000  \n",
       "50%      14.000000    11.000000   321.000000   149.000000     24.000000  \n",
       "75%      14.000000    15.000000   371.000000   169.000000     32.000000  \n",
       "max      44.000000    26.000000   548.000000   216.000000     32.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card4</th>\n",
       "      <th>card6</th>\n",
       "      <th>P_emaildomain</th>\n",
       "      <th>R_emaildomain</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>id_12</th>\n",
       "      <th>id_15</th>\n",
       "      <th>id_16</th>\n",
       "      <th>id_23</th>\n",
       "      <th>id_27</th>\n",
       "      <th>id_28</th>\n",
       "      <th>id_29</th>\n",
       "      <th>id_30</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>590540</td>\n",
       "      <td>588963</td>\n",
       "      <td>588969</td>\n",
       "      <td>496084</td>\n",
       "      <td>137291</td>\n",
       "      <td>319440</td>\n",
       "      <td>319440</td>\n",
       "      <td>319440</td>\n",
       "      <td>309096</td>\n",
       "      <td>240058</td>\n",
       "      <td>421180</td>\n",
       "      <td>244275</td>\n",
       "      <td>244288</td>\n",
       "      <td>244288</td>\n",
       "      <td>144233</td>\n",
       "      <td>140985</td>\n",
       "      <td>129340</td>\n",
       "      <td>5169</td>\n",
       "      <td>5169</td>\n",
       "      <td>140978</td>\n",
       "      <td>140978</td>\n",
       "      <td>77565</td>\n",
       "      <td>140282</td>\n",
       "      <td>73289</td>\n",
       "      <td>77805</td>\n",
       "      <td>140985</td>\n",
       "      <td>140985</td>\n",
       "      <td>140985</td>\n",
       "      <td>140985</td>\n",
       "      <td>140810</td>\n",
       "      <td>118666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>130</td>\n",
       "      <td>260</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>W</td>\n",
       "      <td>visa</td>\n",
       "      <td>debit</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>M0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>Found</td>\n",
       "      <td>Found</td>\n",
       "      <td>IP_PROXY:TRANSPARENT</td>\n",
       "      <td>Found</td>\n",
       "      <td>Found</td>\n",
       "      <td>Found</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>chrome 63.0</td>\n",
       "      <td>1920x1080</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>439670</td>\n",
       "      <td>384767</td>\n",
       "      <td>439938</td>\n",
       "      <td>228355</td>\n",
       "      <td>57147</td>\n",
       "      <td>319415</td>\n",
       "      <td>285468</td>\n",
       "      <td>251731</td>\n",
       "      <td>196405</td>\n",
       "      <td>132491</td>\n",
       "      <td>227856</td>\n",
       "      <td>211374</td>\n",
       "      <td>155251</td>\n",
       "      <td>205656</td>\n",
       "      <td>123025</td>\n",
       "      <td>67728</td>\n",
       "      <td>66324</td>\n",
       "      <td>3489</td>\n",
       "      <td>5155</td>\n",
       "      <td>76232</td>\n",
       "      <td>74926</td>\n",
       "      <td>21155</td>\n",
       "      <td>22000</td>\n",
       "      <td>16874</td>\n",
       "      <td>60011</td>\n",
       "      <td>77814</td>\n",
       "      <td>134066</td>\n",
       "      <td>110452</td>\n",
       "      <td>73922</td>\n",
       "      <td>85165</td>\n",
       "      <td>47722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ProductCD   card4   card6 P_emaildomain R_emaildomain      M1      M2  \\\n",
       "count     590540  588963  588969        496084        137291  319440  319440   \n",
       "unique         5       4       4            59            60       2       2   \n",
       "top            W    visa   debit     gmail.com     gmail.com       T       T   \n",
       "freq      439670  384767  439938        228355         57147  319415  285468   \n",
       "\n",
       "            M3      M4      M5      M6      M7      M8      M9     id_12  \\\n",
       "count   319440  309096  240058  421180  244275  244288  244288    144233   \n",
       "unique       2       3       2       2       2       2       2         2   \n",
       "top          T      M0       F       F       F       F       T  NotFound   \n",
       "freq    251731  196405  132491  227856  211374  155251  205656    123025   \n",
       "\n",
       "         id_15   id_16                 id_23  id_27   id_28   id_29  \\\n",
       "count   140985  129340                  5169   5169  140978  140978   \n",
       "unique       3       2                     3      2       2       2   \n",
       "top      Found   Found  IP_PROXY:TRANSPARENT  Found   Found   Found   \n",
       "freq     67728   66324                  3489   5155   76232   74926   \n",
       "\n",
       "             id_30        id_31      id_33           id_34   id_35   id_36  \\\n",
       "count        77565       140282      73289           77805  140985  140985   \n",
       "unique          75          130        260               4       2       2   \n",
       "top     Windows 10  chrome 63.0  1920x1080  match_status:2       T       F   \n",
       "freq         21155        22000      16874           60011   77814  134066   \n",
       "\n",
       "         id_37   id_38 DeviceType DeviceInfo  \n",
       "count   140985  140985     140810     118666  \n",
       "unique       2       2          2       1786  \n",
       "top          T       F    desktop    Windows  \n",
       "freq    110452   73922      85165      47722  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(include=[np.object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xe061d68>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#distribution of target\n",
    "sns.countplot(x='isFraud',data=train, palette='hls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced classes. We need to fix this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #standardize the numeric variables (except for target)\n",
    "# pd.concat(\n",
    "#     [train.select_dtypes(exclude=[np.number]).reset_index(),\n",
    "#      pd.DataFrame(data=StandardScaler().fit_transform(train.select_dtypes(include=[np.number])),columns=train.select_dtypes(include=[np.number]).columns).reset_index()\n",
    "#     ],\n",
    "#     axis=1\n",
    "# ).drop(columns={'index'}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NA. Lazy version for now. Come back and do this more precisely. Maybe even have 2 models: those with identity and those without\n",
    "# train.fillna(0).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GLM\n",
    "Start with a simple GLM. I like H2Os linear estimator as it provides better insight into the predictors in early model-building stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode)56-b12)\n",
      "  Starting server from C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\MASTED~1\\AppData\\Local\\Temp\\tmpwcf91mbm\n",
      "  JVM stdout: C:\\Users\\MASTED~1\\AppData\\Local\\Temp\\tmpwcf91mbm\\h2o_MasteD17189_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\MASTED~1\\AppData\\Local\\Temp\\tmpwcf91mbm\\h2o_MasteD17189_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>05 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Chicago</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.24.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>2 months and 26 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_MasteD17189_ng2s78</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.531 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.8 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------\n",
       "H2O cluster uptime:         05 secs\n",
       "H2O cluster timezone:       America/Chicago\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.24.0.3\n",
       "H2O cluster version age:    2 months and 26 days\n",
       "H2O cluster name:           H2O_from_python_MasteD17189_ng2s78\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.531 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.8 final\n",
       "--------------------------  ------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "#import into h2o frames\n",
    "trainh2o= h2o.H2OFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainh2o['isFraud']=trainh2o['isFraud'].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=trainh2o.columns\n",
    "varlist=['isFraud','TransactionID','TransactionDT']\n",
    "for var in varlist:\n",
    "    x.remove(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=['DeviceType','DeviceInfo','TransactionAmt','card1','card2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtrain,subtest=trainh2o.split_frame(ratios=[0.70], seed=413)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class H2OGeneralizedLinearEstimator in module h2o.estimators.glm:\n",
      "\n",
      "class H2OGeneralizedLinearEstimator(h2o.estimators.estimator_base.H2OEstimator)\n",
      " |  Generalized Linear Modeling\n",
      " |  \n",
      " |  Fits a generalized linear model, specified by a response variable, a set of predictors, and a\n",
      " |  description of the error distribution.\n",
      " |  \n",
      " |  A subclass of :class:`ModelBase` is returned. The specific subclass depends on the machine learning task\n",
      " |  at hand (if it's binomial classification, then an H2OBinomialModel is returned, if it's regression then a\n",
      " |  H2ORegressionModel is returned). The default print-out of the models is shown, but further GLM-specific\n",
      " |  information can be queried out of the object. Upon completion of the GLM, the resulting object has\n",
      " |  coefficients, normalized coefficients, residual/null deviance, aic, and a host of model metrics including\n",
      " |  MSE, AUC (for logistic regression), degrees of freedom, and confusion matrices.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      H2OGeneralizedLinearEstimator\n",
      " |      h2o.estimators.estimator_base.H2OEstimator\n",
      " |      h2o.model.model_base.ModelBase\n",
      " |      h2o.utils.backward_compatibility.BackwardsCompatibleBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |      Construct a new model instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  getGLMRegularizationPath(model)\n",
      " |      Extract full regularization path explored during lambda search from glm model.\n",
      " |      \n",
      " |      :param model: source lambda search model\n",
      " |  \n",
      " |  makeGLMModel(model, coefs, threshold=0.5)\n",
      " |      Create a custom GLM model using the given coefficients.\n",
      " |      \n",
      " |      Needs to be passed source model trained on the dataset to extract the dataset information from.\n",
      " |      \n",
      " |      :param model: source model, used for extracting dataset information\n",
      " |      :param coefs: dictionary containing model coefficients\n",
      " |      :param threshold: (optional, only for binomial) decision threshold used for classification\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  Lambda\n",
      " |      DEPRECATED. Use ``self.lambda_`` instead\n",
      " |  \n",
      " |  alpha\n",
      " |      Distribution of regularization between the L1 (Lasso) and L2 (Ridge) penalties. A value of 1 for alpha\n",
      " |      represents Lasso regression, a value of 0 produces Ridge regression, and anything in between specifies the\n",
      " |      amount of mixing between the two. Default value of alpha is 0 when SOLVER = 'L-BFGS'; 0.5 otherwise.\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  balance_classes\n",
      " |      Balance training data class counts via over/under-sampling (for imbalanced data).\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  beta_constraints\n",
      " |      Beta constraints\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  beta_epsilon\n",
      " |      Converge if  beta changes less (using L-infinity norm) than beta esilon, ONLY applies to IRLSM solver\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.0001``).\n",
      " |  \n",
      " |  class_sampling_factors\n",
      " |      Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will\n",
      " |      be automatically computed to obtain class balance during training. Requires balance_classes.\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  compute_p_values\n",
      " |      Request p-values computation, p-values work only with IRLSM solver and no regularization\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  custom_metric_func\n",
      " |      Reference to custom evaluation function, format: `language:keyName=funcName`\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  early_stopping\n",
      " |      Stop early when there is no more relative improvement on train or validation (if provided)\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  export_checkpoints_dir\n",
      " |      Automatically export generated models to this directory.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  family\n",
      " |      Family. Use binomial for classification with logistic regression, others are for regression problems.\n",
      " |      \n",
      " |      One of: ``\"gaussian\"``, ``\"binomial\"``, ``\"quasibinomial\"``, ``\"ordinal\"``, ``\"multinomial\"``, ``\"poisson\"``,\n",
      " |      ``\"gamma\"``, ``\"tweedie\"``, ``\"negativebinomial\"``  (default: ``\"gaussian\"``).\n",
      " |  \n",
      " |  fold_assignment\n",
      " |      Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will stratify\n",
      " |      the folds based on the response variable, for classification problems.\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"random\"``, ``\"modulo\"``, ``\"stratified\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  fold_column\n",
      " |      Column with cross-validation fold index assignment per observation.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  gradient_epsilon\n",
      " |      Converge if  objective changes less (using L-infinity norm) than this, ONLY applies to L-BFGS solver. Default\n",
      " |      indicates: If lambda_search is set to False and lambda is equal to zero, the default value of gradient_epsilon\n",
      " |      is equal to .000001, otherwise the default value is .0001. If lambda_search is set to True, the conditional\n",
      " |      values above are 1E-8 and 1E-6 respectively.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``-1``).\n",
      " |  \n",
      " |  ignore_const_cols\n",
      " |      Ignore constant columns.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  ignored_columns\n",
      " |      Names of columns to ignore for training.\n",
      " |      \n",
      " |      Type: ``List[str]``.\n",
      " |  \n",
      " |  interaction_pairs\n",
      " |      A list of pairwise (first order) column interactions.\n",
      " |      \n",
      " |      Type: ``List[tuple]``.\n",
      " |  \n",
      " |  interactions\n",
      " |      A list of predictor column indices to interact. All pairwise combinations will be computed for the list.\n",
      " |      \n",
      " |      Type: ``List[str]``.\n",
      " |  \n",
      " |  intercept\n",
      " |      Include constant term in the model\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  keep_cross_validation_fold_assignment\n",
      " |      Whether to keep the cross-validation fold assignment.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  keep_cross_validation_models\n",
      " |      Whether to keep the cross-validation models.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  keep_cross_validation_predictions\n",
      " |      Whether to keep the predictions of the cross-validation models.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  lambda_\n",
      " |      Regularization strength\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  lambda_min_ratio\n",
      " |      Minimum lambda used in lambda search, specified as a ratio of lambda_max (the smallest lambda that drives all\n",
      " |      coefficients to zero). Default indicates: if the number of observations is greater than the number of variables,\n",
      " |      then lambda_min_ratio is set to 0.0001; if the number of observations is less than the number of variables, then\n",
      " |      lambda_min_ratio is set to 0.01.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``-1``).\n",
      " |  \n",
      " |  lambda_search\n",
      " |      Use lambda search starting at lambda max, given lambda is then interpreted as lambda min\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  link\n",
      " |      One of: ``\"family_default\"``, ``\"identity\"``, ``\"logit\"``, ``\"log\"``, ``\"inverse\"``, ``\"tweedie\"``,\n",
      " |      ``\"ologit\"``, ``\"oprobit\"``, ``\"ologlog\"``  (default: ``\"family_default\"``).\n",
      " |  \n",
      " |  max_active_predictors\n",
      " |      Maximum number of active predictors during computation. Use as a stopping criterion to prevent expensive model\n",
      " |      building with many predictors. Default indicates: If the IRLSM solver is used, the value of\n",
      " |      max_active_predictors is set to 5000 otherwise it is set to 100000000.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  max_after_balance_size\n",
      " |      Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires\n",
      " |      balance_classes.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``5``).\n",
      " |  \n",
      " |  max_confusion_matrix_size\n",
      " |      [Deprecated] Maximum size (# classes) for confusion matrices to be printed in the Logs\n",
      " |      \n",
      " |      Type: ``int``  (default: ``20``).\n",
      " |  \n",
      " |  max_hit_ratio_k\n",
      " |      Maximum number (top K) of predictions to use for hit ratio computation (for multi-class only, 0 to disable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  max_iterations\n",
      " |      Maximum number of iterations\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  max_runtime_secs\n",
      " |      Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  missing_values_handling\n",
      " |      Handling of missing values. Either MeanImputation or Skip.\n",
      " |      \n",
      " |      One of: ``\"mean_imputation\"``, ``\"skip\"``  (default: ``\"mean_imputation\"``).\n",
      " |  \n",
      " |  nfolds\n",
      " |      Number of folds for K-fold cross-validation (0 to disable or >= 2).\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  nlambdas\n",
      " |      Number of lambdas to be used in a search. Default indicates: If alpha is zero, with lambda search set to True,\n",
      " |      the value of nlamdas is set to 30 (fewer lambdas are needed for ridge regression) otherwise it is set to 100.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  non_negative\n",
      " |      Restrict coefficients (not intercept) to be non-negative\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  obj_reg\n",
      " |      Likelihood divider in objective value computation, default is 1/nobs\n",
      " |      \n",
      " |      Type: ``float``  (default: ``-1``).\n",
      " |  \n",
      " |  objective_epsilon\n",
      " |      Converge if  objective value changes less than this. Default indicates: If lambda_search is set to True the\n",
      " |      value of objective_epsilon is set to .0001. If the lambda_search is set to False and lambda is equal to zero,\n",
      " |      the value of objective_epsilon is set to .000001, for any other value of lambda the default value of\n",
      " |      objective_epsilon is set to .0001.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``-1``).\n",
      " |  \n",
      " |  offset_column\n",
      " |      Offset column. This will be added to the combination of columns before applying the link function.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  prior\n",
      " |      Prior probability for y==1. To be used only for logistic regression iff the data has been sampled and the mean\n",
      " |      of response does not reflect reality.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``-1``).\n",
      " |  \n",
      " |  remove_collinear_columns\n",
      " |      In case of linearly dependent columns, remove some of the dependent columns\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  response_column\n",
      " |      Response variable column.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  score_each_iteration\n",
      " |      Whether to score during each iteration of model training.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  seed\n",
      " |      Seed for pseudo random number generator (if applicable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  solver\n",
      " |      AUTO will set the solver based on given data and the other parameters. IRLSM is fast on on problems with small\n",
      " |      number of predictors and for lambda-search with L1 penalty, L_BFGS scales better for datasets with many columns.\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"irlsm\"``, ``\"l_bfgs\"``, ``\"coordinate_descent_naive\"``, ``\"coordinate_descent\"``,\n",
      " |      ``\"gradient_descent_lh\"``, ``\"gradient_descent_sqerr\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  standardize\n",
      " |      Standardize numeric columns to have zero mean and unit variance\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  theta\n",
      " |      Theta\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1e-10``).\n",
      " |  \n",
      " |  training_frame\n",
      " |      Id of the training data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  tweedie_link_power\n",
      " |      Tweedie link power\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  tweedie_variance_power\n",
      " |      Tweedie variance power\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  validation_frame\n",
      " |      Id of the validation data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  weights_column\n",
      " |      Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from the\n",
      " |      dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative\n",
      " |      weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the data\n",
      " |      frame. This is typically the number of times a row is repeated, but non-integer values are supported as well.\n",
      " |      During training, rows with higher weights matter more, due to the larger loss function pre-factor.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  algo = 'glm'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  convert_H2OXGBoostParams_2_XGBoostParams(self)\n",
      " |      In order to use convert_H2OXGBoostParams_2_XGBoostParams and convert_H2OFrame_2_DMatrix, you must import\n",
      " |      the following toolboxes: xgboost, pandas, numpy and scipy.sparse.\n",
      " |      \n",
      " |      Given an H2OXGBoost model, this method will generate the corresponding parameters that should be used by\n",
      " |      native XGBoost in order to give exactly the same result, assuming that the same dataset\n",
      " |      (derived from h2oFrame) is used to train the native XGBoost model.\n",
      " |      \n",
      " |      Follow the steps below to compare H2OXGBoost and native XGBoost:\n",
      " |      \n",
      " |      1. Train the H2OXGBoost model with H2OFrame trainFile and generate a prediction:\n",
      " |      h2oModelD = H2OXGBoostEstimator(**h2oParamsD) # parameters specified as a dict()\n",
      " |      h2oModelD.train(x=myX, y=y, training_frame=trainFile) # train with H2OFrame trainFile\n",
      " |      h2oPredict = h2oPredictD = h2oModelD.predict(trainFile)\n",
      " |      \n",
      " |      2. Derive the DMatrix from H2OFrame:\n",
      " |      nativeDMatrix = trainFile.convert_H2OFrame_2_DMatrix(myX, y, h2oModelD)\n",
      " |      \n",
      " |      3. Derive the parameters for native XGBoost:\n",
      " |      nativeParams = h2oModelD.convert_H2OXGBoostParams_2_XGBoostParams()\n",
      " |      \n",
      " |      4. Train your native XGBoost model and generate a prediction:\n",
      " |      nativeModel = xgb.train(params=nativeParams[0], dtrain=nativeDMatrix, num_boost_round=nativeParams[1])\n",
      " |      nativePredict = nativeModel.predict(data=nativeDMatrix, ntree_limit=nativeParams[1].\n",
      " |      \n",
      " |      5. Compare the predictions h2oPredict from H2OXGBoost, nativePredict from native XGBoost.\n",
      " |      \n",
      " |      :return: nativeParams, num_boost_round\n",
      " |  \n",
      " |  fit(self, X, y=None, **params)\n",
      " |      Fit an H2O model as part of a scikit-learn pipeline or grid search.\n",
      " |      \n",
      " |      A warning will be issued if a caller other than sklearn attempts to use this method.\n",
      " |      \n",
      " |      :param H2OFrame X: An H2OFrame consisting of the predictor variables.\n",
      " |      :param H2OFrame y: An H2OFrame consisting of the response variable.\n",
      " |      :param params: Extra arguments.\n",
      " |      :returns: The current instance of H2OEstimator for method chaining.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Obtain parameters for this estimator.\n",
      " |      \n",
      " |      Used primarily for sklearn Pipelines and sklearn grid search.\n",
      " |      \n",
      " |      :param deep: If True, return parameters of all sub-objects that are estimators.\n",
      " |      \n",
      " |      :returns: A dict of parameters\n",
      " |  \n",
      " |  join(self)\n",
      " |      Wait until job's completion.\n",
      " |  \n",
      " |  set_params(self, **parms)\n",
      " |      Used by sklearn for updating parameters during grid search.\n",
      " |      \n",
      " |      :param parms: A dictionary of parameters that will be set on this model.\n",
      " |      :returns: self, the current estimator object with the parameters all set as desired.\n",
      " |  \n",
      " |  start(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
      " |      Train the model asynchronously (to block for results call :meth:`join`).\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |  \n",
      " |  train(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, max_runtime_secs=None, ignored_columns=None, model_id=None, verbose=False)\n",
      " |      Train the H2O model.\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |      :param float max_runtime_secs: Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      :param bool verbose: Print scoring history to stdout. Defaults to False.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  mixin(obj, cls)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  aic(self, train=False, valid=False, xval=False)\n",
      " |      Get the AIC (Akaike Information Criterium).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AIC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AIC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AIC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AIC.\n",
      " |  \n",
      " |  auc(self, train=False, valid=False, xval=False)\n",
      " |      Get the AUC (Area Under Curve).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AUC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AUC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AUC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AUC.\n",
      " |  \n",
      " |  biases(self, vector_id=0)\n",
      " |      Return the frame for the respective bias vector.\n",
      " |      \n",
      " |      :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the bias vector identified by vector_id\n",
      " |  \n",
      " |  catoffsets(self)\n",
      " |      Categorical offsets for one-hot encoding.\n",
      " |  \n",
      " |  coef(self)\n",
      " |      Return the coefficients which can be applied to the non-standardized data.\n",
      " |      \n",
      " |      Note: standardize = True by default, if set to False then coef() return the coefficients which are fit directly.\n",
      " |  \n",
      " |  coef_norm(self)\n",
      " |      Return coefficients fitted on the standardized data (requires standardize = True, which is on by default).\n",
      " |      \n",
      " |      These coefficients can be used to evaluate variable importance.\n",
      " |  \n",
      " |  cross_validation_fold_assignment(self)\n",
      " |      Obtain the cross-validation fold assignment for all rows in the training data.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_holdout_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on the training data.\n",
      " |      \n",
      " |      This is equivalent to summing up all H2OFrames returned by cross_validation_predictions.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_metrics_summary(self)\n",
      " |      Retrieve Cross-Validation Metrics Summary.\n",
      " |      \n",
      " |      :returns: The cross-validation metrics summary as an H2OTwoDimTable\n",
      " |  \n",
      " |  cross_validation_models(self)\n",
      " |      Obtain a list of cross-validation models.\n",
      " |      \n",
      " |      :returns: list of H2OModel objects.\n",
      " |  \n",
      " |  cross_validation_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on their holdout data.\n",
      " |      \n",
      " |      Note that the predictions are expanded to the full number of rows of the training data, with 0 fill-in.\n",
      " |      \n",
      " |      :returns: list of H2OFrame objects.\n",
      " |  \n",
      " |  deepfeatures(self, test_data, layer)\n",
      " |      Return hidden layer details.\n",
      " |      \n",
      " |      :param test_data: Data to create a feature space on\n",
      " |      :param layer: 0 index hidden layer\n",
      " |  \n",
      " |  download_mojo(self, path='.', get_genmodel_jar=False, genmodel_name='')\n",
      " |      Download the model in MOJO format.\n",
      " |      \n",
      " |      :param path: the path where MOJO file should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name Custom name of genmodel jar\n",
      " |      :returns: name of the MOJO file written.\n",
      " |  \n",
      " |  download_pojo(self, path='', get_genmodel_jar=False, genmodel_name='')\n",
      " |      Download the POJO for this model to the directory specified by path.\n",
      " |      \n",
      " |      If path is an empty string, then dump the output to screen.\n",
      " |      \n",
      " |      :param path:  An absolute path to the directory where POJO should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name Custom name of genmodel jar\n",
      " |      :returns: name of the POJO file written.\n",
      " |  \n",
      " |  get_xval_models(self, key=None)\n",
      " |      Return a Model object.\n",
      " |      \n",
      " |      :param key: If None, return all cross-validated models; otherwise return the model that key points to.\n",
      " |      \n",
      " |      :returns: A model or list of models.\n",
      " |  \n",
      " |  gini(self, train=False, valid=False, xval=False)\n",
      " |      Get the Gini coefficient.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\"\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Gini Coefficient value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Gini Coefficient value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Gini Coefficient value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Gini Coefficient for this binomial model.\n",
      " |  \n",
      " |  is_cross_validated(self)\n",
      " |      Return True if the model was cross-validated.\n",
      " |  \n",
      " |  logloss(self, train=False, valid=False, xval=False)\n",
      " |      Get the Log Loss.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the log loss value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the log loss value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the log loss value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The log loss for this regression model.\n",
      " |  \n",
      " |  mae(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Absolute Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MAE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MAE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MAE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MAE for this regression model.\n",
      " |  \n",
      " |  mean_residual_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Residual Deviances.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Mean Residual Deviance value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Mean Residual Deviance value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Mean Residual Deviance value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Mean Residual Deviance for this regression model.\n",
      " |  \n",
      " |  model_performance(self, test_data=None, train=False, valid=False, xval=False)\n",
      " |      Generate model metrics for this model on test_data.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data set for which model metrics shall be computed against. All three of train,\n",
      " |          valid and xval arguments are ignored if test_data is not None.\n",
      " |      :param bool train: Report the training metrics for the model.\n",
      " |      :param bool valid: Report the validation metrics for the model.\n",
      " |      :param bool xval: Report the cross-validation metrics for the model. If train and valid are True, then it\n",
      " |          defaults to True.\n",
      " |      \n",
      " |      :returns: An object of class H2OModelMetrics.\n",
      " |  \n",
      " |  mse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MSE for this regression model.\n",
      " |  \n",
      " |  normmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric predictors.\n",
      " |  \n",
      " |  normsub(self)\n",
      " |      Normalization/Standardization offsets for numeric predictors.\n",
      " |  \n",
      " |  null_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null dof for the training set. If both train and valid are False, then train is\n",
      " |          selected by default.\n",
      " |      :param bool valid: Get the null dof for the validation set. If both train and valid are True, then train is\n",
      " |          selected by default.\n",
      " |      \n",
      " |      :returns: Return the null dof, or None if it is not present.\n",
      " |  \n",
      " |  null_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null deviance for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the null deviance for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the null deviance, or None if it is not present.\n",
      " |  \n",
      " |  partial_plot(self, data, cols, destination_key=None, nbins=20, weight_column=None, plot=True, plot_stddev=True, figsize=(7, 10), server=False, include_na=False, user_splits=None, save_to_file=None)\n",
      " |      Create partial dependence plot which gives a graphical depiction of the marginal effect of a variable on the\n",
      " |      response. The effect of a variable is measured in change in the mean response.\n",
      " |      \n",
      " |      :param H2OFrame data: An H2OFrame object used for scoring and constructing the plot.\n",
      " |      :param cols: Feature(s) for which partial dependence will be calculated.\n",
      " |      :param destination_key: An key reference to the created partial dependence tables in H2O.\n",
      " |      :param nbins: Number of bins used. For categorical columns make sure the number of bins exceed the level count. If you enable add_missing_NA, the returned length will be nbin+1.\n",
      " |      :param weight_column: A string denoting which column of data should be used as the weight column.\n",
      " |      :param plot: A boolean specifying whether to plot partial dependence table.\n",
      " |      :param plot_stddev: A boolean specifying whether to add std err to partial dependence plot.\n",
      " |      :param figsize: Dimension/size of the returning plots, adjust to fit your output cells.\n",
      " |      :param server: ?\n",
      " |      :param include_na: A boolean specifying whether missing value should be included in the Feature values.\n",
      " |      :param user_splits: a dictionary containing column names as key and user defined split values as value in a list.\n",
      " |      :param save_to_file Fully qualified name to an image file the resulting plot should be saved to, e.g. '/home/user/pdpplot.png'. The 'png' postfix might be omitted. If the file already exists, it will be overridden. Plot is only saved if plot = True.\n",
      " |      :returns: Plot and list of calculated mean response tables for each feature requested.\n",
      " |  \n",
      " |  pprint_coef(self)\n",
      " |      Pretty print the coefficents table (includes normalized coefficients).\n",
      " |  \n",
      " |  predict(self, test_data, custom_metric=None, custom_metric_func=None)\n",
      " |      Predict on a dataset.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      :param custom_metric:  custom evaluation function defined as class reference, the class get uploaded\n",
      " |      into cluster\n",
      " |      :param custom_metric_func: custom evaluation function reference, e.g, result of upload_custom_metric\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  predict_contributions(self, test_data)\n",
      " |      Predict feature contributions - SHAP values on an H2O Model (only GBM and XGBoost models).\n",
      " |      \n",
      " |      Returned H2OFrame has shape (#rows, #features + 1) - there is a feature contribution column for each input\n",
      " |      feature, the last column is the model bias (same value for each row). The sum of the feature contributions\n",
      " |      and the bias term is equal to the raw prediction of the model. Raw prediction of tree-based model is the sum \n",
      " |      of the predictions of the individual trees before before the inverse link function is applied to get the actual\n",
      " |      prediction. For Gaussian distribution the sum of the contributions is equal to the model prediction. \n",
      " |      \n",
      " |      Note: Multinomial classification models are currently not supported.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to calculate contributions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame made of feature contributions.\n",
      " |  \n",
      " |  predict_leaf_node_assignment(self, test_data, type='Path')\n",
      " |      Predict on a dataset and return the leaf node assignment (only for tree-based models).\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      :param Enum type: How to identify the leaf node. Nodes can be either identified by a path from to the root node\n",
      " |      of the tree to the node or by H2O's internal node id. One of: ``\"Path\"``, ``\"Node_ID\"`` (default: ``\"Path\"``).\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  r2(self, train=False, valid=False, xval=False)\n",
      " |      Return the R squared for this regression model.\n",
      " |      \n",
      " |      Will return R^2 for GLM Models and will return NaN otherwise.\n",
      " |      \n",
      " |      The R^2 value is defined to be 1 - MSE/var, where var is computed as sigma*sigma.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the R^2 value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the R^2 value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the R^2 value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The R squared for this regression model.\n",
      " |  \n",
      " |  residual_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual dof for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the residual dof for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual dof, or None if it is not present.\n",
      " |  \n",
      " |  residual_deviance(self, train=False, valid=False, xval=None)\n",
      " |      Retreive the residual deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual deviance for the training set. If both train and valid are False, then\n",
      " |          train is selected by default.\n",
      " |      :param bool valid: Get the residual deviance for the validation set. If both train and valid are True, then\n",
      " |          train is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual deviance, or None if it is not present.\n",
      " |  \n",
      " |  respmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric response.\n",
      " |  \n",
      " |  respsub(self)\n",
      " |      Normalization/Standardization offsets for numeric response.\n",
      " |  \n",
      " |  rmse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSE for this regression model.\n",
      " |  \n",
      " |  rmsle(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Squared Logarithmic Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSLE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSLE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSLE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSLE for this regression model.\n",
      " |  \n",
      " |  rotation(self)\n",
      " |      Obtain the rotations (eigenvectors) for a PCA model\n",
      " |      \n",
      " |      :return: H2OFrame\n",
      " |  \n",
      " |  save_model_details(self, path='', force=False)\n",
      " |      Save Model Details of an H2O Model in JSON Format to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model details at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model details\n",
      " |  \n",
      " |  save_mojo(self, path='', force=False)\n",
      " |      Save an H2O Model as MOJO (Model Object, Optimized) to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model\n",
      " |  \n",
      " |  score_history(self)\n",
      " |      DEPRECATED. Use :meth:`scoring_history` instead.\n",
      " |  \n",
      " |  scoring_history(self)\n",
      " |      Retrieve Model Score History.\n",
      " |      \n",
      " |      :returns: The score history as an H2OTwoDimTable or a Pandas DataFrame.\n",
      " |  \n",
      " |  show(self)\n",
      " |      Print innards of model, without regards to type.\n",
      " |  \n",
      " |  staged_predict_proba(self, test_data)\n",
      " |      Predict class probabilities at each stage of an H2O Model (only GBM models).\n",
      " |      \n",
      " |      The output structure is analogous to the output of function predict_leaf_node_assignment. For each tree t and\n",
      " |      class c there will be a column Tt.Cc (eg. T3.C1 for tree 3 and class 1). The value will be the corresponding\n",
      " |      predicted probability of this class by combining the raw contributions of trees T1.Cc,..,TtCc. Binomial models\n",
      " |      build the trees just for the first class and values in columns Tx.C1 thus correspond to the the probability p0.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame of staged predictions.\n",
      " |  \n",
      " |  std_coef_plot(self, num_of_features=None, server=False)\n",
      " |      Plot a GLM model\"s standardized coefficient magnitudes.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot.\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  summary(self)\n",
      " |      Print a detailed summary of the model.\n",
      " |  \n",
      " |  varimp(self, use_pandas=False)\n",
      " |      Pretty print the variable importances, or return them in a list.\n",
      " |      \n",
      " |      :param use_pandas: If True, then the variable importances will be returned as a pandas data frame.\n",
      " |      \n",
      " |      :returns: A list or Pandas DataFrame.\n",
      " |  \n",
      " |  varimp_plot(self, num_of_features=None, server=False)\n",
      " |      Plot the variable importance for a trained model.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot (default is 10 or all if less than 10).\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  weights(self, matrix_id=0)\n",
      " |      Return the frame for the respective weight matrix.\n",
      " |      \n",
      " |      :param: matrix_id: an integer, ranging from 0 to number of layers, that specifies the weight matrix to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the weight matrix identified by matrix_id\n",
      " |  \n",
      " |  xval_keys(self)\n",
      " |      Return model keys for the cross-validated model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  actual_params\n",
      " |      Dictionary of actual parameters of the model.\n",
      " |  \n",
      " |  default_params\n",
      " |      Dictionary of the default parameters of the model.\n",
      " |  \n",
      " |  end_time\n",
      " |      Timestamp (milliseconds since 1970) when the model training was ended.\n",
      " |  \n",
      " |  full_parameters\n",
      " |      Dictionary of the full specification of all parameters.\n",
      " |  \n",
      " |  have_mojo\n",
      " |      True, if export to MOJO is possible\n",
      " |  \n",
      " |  have_pojo\n",
      " |      True, if export to POJO is possible\n",
      " |  \n",
      " |  model_id\n",
      " |      Model identifier.\n",
      " |  \n",
      " |  params\n",
      " |      Get the parameters and the actual/default values only.\n",
      " |      \n",
      " |      :returns: A dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  run_time\n",
      " |      Model training time in milliseconds\n",
      " |  \n",
      " |  start_time\n",
      " |      Timestamp (milliseconds since 1970) when the model training was started.\n",
      " |  \n",
      " |  type\n",
      " |      The type of model built: ``\"classifier\"`` or ``\"regressor\"`` or ``\"unsupervised\"``\n",
      " |  \n",
      " |  xvals\n",
      " |      Return a list of the cross-validated models.\n",
      " |      \n",
      " |      :returns: A list of models.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __getattr__(self, item)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(H2OGeneralizedLinearEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_model_reg = H2OGeneralizedLinearEstimator(\n",
    "    family= \"binomial\",\n",
    "    balance_classes=True,\n",
    "    lambda_ = 0.0001, \n",
    "    compute_p_values = False,\n",
    "    remove_collinear_columns=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "glm_model_reg.train(\n",
    "    x,'isFraud', training_frame= subtrain, validation_frame=subtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>coefficients</th>\n",
       "      <th>standardized_coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>DeviceInfo.hi6210sft Build/MRA58K</td>\n",
       "      <td>4.170816</td>\n",
       "      <td>4.170816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>DeviceInfo.SM-A300H Build/LRX22G</td>\n",
       "      <td>3.243428</td>\n",
       "      <td>3.243428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>DeviceType.mobile</td>\n",
       "      <td>1.937616</td>\n",
       "      <td>1.937616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>DeviceType.desktop</td>\n",
       "      <td>1.929817</td>\n",
       "      <td>1.929817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>DeviceInfo.nan</td>\n",
       "      <td>0.039829</td>\n",
       "      <td>0.039829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>TransactionAmt</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.155548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>card1</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.080006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>card2</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>-0.058020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>DeviceInfo.rv:57.0</td>\n",
       "      <td>-0.076484</td>\n",
       "      <td>-0.076484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>DeviceInfo.Windows</td>\n",
       "      <td>-0.652804</td>\n",
       "      <td>-0.652804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>DeviceInfo.iOS Device</td>\n",
       "      <td>-0.744454</td>\n",
       "      <td>-0.744454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>DeviceInfo.MacOS</td>\n",
       "      <td>-1.870768</td>\n",
       "      <td>-1.870768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>DeviceInfo.Trident/7.0</td>\n",
       "      <td>-2.265892</td>\n",
       "      <td>-2.265892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-3.664754</td>\n",
       "      <td>-3.870740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  names  coefficients  \\\n",
       "1726  DeviceInfo.hi6210sft Build/MRA58K      4.170816   \n",
       "1126   DeviceInfo.SM-A300H Build/LRX22G      3.243428   \n",
       "1789                  DeviceType.mobile      1.937616   \n",
       "1788                 DeviceType.desktop      1.929817   \n",
       "1743                     DeviceInfo.nan      0.039829   \n",
       "1791                     TransactionAmt      0.000656   \n",
       "1792                              card1     -0.000016   \n",
       "1793                              card2     -0.000368   \n",
       "1771                 DeviceInfo.rv:57.0     -0.076484   \n",
       "1599                 DeviceInfo.Windows     -0.652804   \n",
       "1728              DeviceInfo.iOS Device     -0.744454   \n",
       "724                    DeviceInfo.MacOS     -1.870768   \n",
       "1553             DeviceInfo.Trident/7.0     -2.265892   \n",
       "0                             Intercept     -3.664754   \n",
       "\n",
       "      standardized_coefficients  \n",
       "1726                   4.170816  \n",
       "1126                   3.243428  \n",
       "1789                   1.937616  \n",
       "1788                   1.929817  \n",
       "1743                   0.039829  \n",
       "1791                   0.155548  \n",
       "1792                  -0.080006  \n",
       "1793                  -0.058020  \n",
       "1771                  -0.076484  \n",
       "1599                  -0.652804  \n",
       "1728                  -0.744454  \n",
       "724                   -1.870768  \n",
       "1553                  -2.265892  \n",
       "0                     -3.870740  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_out=glm_model_reg._model_json['output']['coefficients_table'].as_data_frame()\n",
    "coef_out[np.abs(coef_out.coefficients)>0].sort_values(by='coefficients', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the top 10\n",
    "glm_model_reg.std_coef_plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
      "Model Key:  GLM_model_python_1564778894347_21\n",
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.032547937564081274\n",
      "RMSE: 0.18041046966315805\n",
      "LogLoss: 0.14035470868237837\n",
      "Null degrees of freedom: 413604\n",
      "Residual degrees of freedom: 413591\n",
      "Null deviance: 126048.66865040193\n",
      "Residual deviance: 116102.81856915021\n",
      "AIC: 116130.81856915021\n",
      "AUC: 0.7038748631916821\n",
      "pr_auc: 0.11642298427926562\n",
      "Gini: 0.40774972638336426\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1122739401966155: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>374356.0</td>\n",
       "<td>24690.0</td>\n",
       "<td>0.0619</td>\n",
       "<td> (24690.0/399046.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>10511.0</td>\n",
       "<td>4048.0</td>\n",
       "<td>0.722</td>\n",
       "<td> (10511.0/14559.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>384867.0</td>\n",
       "<td>28738.0</td>\n",
       "<td>0.0851</td>\n",
       "<td> (35201.0/413605.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      374356  24690  0.0619   (24690.0/399046.0)\n",
       "1      10511   4048   0.722    (10511.0/14559.0)\n",
       "Total  384867  28738  0.0851   (35201.0/413605.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1122739</td>\n",
       "<td>0.1869876</td>\n",
       "<td>140.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0609728</td>\n",
       "<td>0.2728970</td>\n",
       "<td>242.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.1235951</td>\n",
       "<td>0.1644504</td>\n",
       "<td>113.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7478170</td>\n",
       "<td>0.9653026</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.8885705</td>\n",
       "<td>0.9384615</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0114909</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9999975</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0683845</td>\n",
       "<td>0.1593809</td>\n",
       "<td>219.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0235391</td>\n",
       "<td>0.6554022</td>\n",
       "<td>330.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0268040</td>\n",
       "<td>0.6726363</td>\n",
       "<td>313.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.112274     0.186988  140\n",
       "max f2                       0.0609728    0.272897  242\n",
       "max f0point5                 0.123595     0.16445   113\n",
       "max accuracy                 0.747817     0.965303  18\n",
       "max precision                0.888571     0.938462  3\n",
       "max recall                   0.0114909    1         398\n",
       "max specificity              1            0.999997  0\n",
       "max absolute_mcc             0.0683845    0.159381  219\n",
       "max min_per_class_accuracy   0.0235391    0.655402  330\n",
       "max mean_per_class_accuracy  0.026804     0.672636  313"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  3.52 %, avg score:  3.64 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100071</td>\n",
       "<td>0.1358778</td>\n",
       "<td>5.9576987</td>\n",
       "<td>5.9576987</td>\n",
       "<td>0.2097125</td>\n",
       "<td>0.1923107</td>\n",
       "<td>0.2097125</td>\n",
       "<td>0.1923107</td>\n",
       "<td>0.0596195</td>\n",
       "<td>0.0596195</td>\n",
       "<td>495.7698662</td>\n",
       "<td>495.7698662</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200022</td>\n",
       "<td>0.1310425</td>\n",
       "<td>4.3774702</td>\n",
       "<td>5.1680619</td>\n",
       "<td>0.1540881</td>\n",
       "<td>0.1330423</td>\n",
       "<td>0.1819171</td>\n",
       "<td>0.1626944</td>\n",
       "<td>0.0437530</td>\n",
       "<td>0.1033725</td>\n",
       "<td>337.7470159</td>\n",
       "<td>416.8061936</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300021</td>\n",
       "<td>0.1280943</td>\n",
       "<td>4.1212120</td>\n",
       "<td>4.8191401</td>\n",
       "<td>0.1450677</td>\n",
       "<td>0.1293953</td>\n",
       "<td>0.1696349</td>\n",
       "<td>0.1515956</td>\n",
       "<td>0.0412116</td>\n",
       "<td>0.1445841</td>\n",
       "<td>312.1211988</td>\n",
       "<td>381.9140074</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400019</td>\n",
       "<td>0.1256030</td>\n",
       "<td>3.3931312</td>\n",
       "<td>4.4626594</td>\n",
       "<td>0.1194391</td>\n",
       "<td>0.1270214</td>\n",
       "<td>0.1570867</td>\n",
       "<td>0.1454524</td>\n",
       "<td>0.0339309</td>\n",
       "<td>0.1785150</td>\n",
       "<td>239.3131204</td>\n",
       "<td>346.2659404</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500187</td>\n",
       "<td>0.1211245</td>\n",
       "<td>4.0251067</td>\n",
       "<td>4.3750347</td>\n",
       "<td>0.1416848</td>\n",
       "<td>0.1234034</td>\n",
       "<td>0.1540023</td>\n",
       "<td>0.1410369</td>\n",
       "<td>0.0403187</td>\n",
       "<td>0.2188337</td>\n",
       "<td>302.5106744</td>\n",
       "<td>337.5034662</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000012</td>\n",
       "<td>0.0780243</td>\n",
       "<td>2.4007317</td>\n",
       "<td>3.3882412</td>\n",
       "<td>0.0845064</td>\n",
       "<td>0.1063341</td>\n",
       "<td>0.1192669</td>\n",
       "<td>0.1236918</td>\n",
       "<td>0.1199945</td>\n",
       "<td>0.3388282</td>\n",
       "<td>140.0731741</td>\n",
       "<td>238.8241202</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1501312</td>\n",
       "<td>0.0656007</td>\n",
       "<td>2.0908635</td>\n",
       "<td>2.9550368</td>\n",
       "<td>0.0735989</td>\n",
       "<td>0.0705603</td>\n",
       "<td>0.1040180</td>\n",
       "<td>0.1059507</td>\n",
       "<td>0.1048149</td>\n",
       "<td>0.4436431</td>\n",
       "<td>109.0863463</td>\n",
       "<td>195.5036757</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000024</td>\n",
       "<td>0.0559375</td>\n",
       "<td>1.5535573</td>\n",
       "<td>2.6055733</td>\n",
       "<td>0.0546856</td>\n",
       "<td>0.0610462</td>\n",
       "<td>0.0917168</td>\n",
       "<td>0.0947536</td>\n",
       "<td>0.0774778</td>\n",
       "<td>0.5211210</td>\n",
       "<td>55.3557262</td>\n",
       "<td>160.5573282</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000036</td>\n",
       "<td>0.0245947</td>\n",
       "<td>1.0076120</td>\n",
       "<td>2.0729195</td>\n",
       "<td>0.0354682</td>\n",
       "<td>0.0309314</td>\n",
       "<td>0.0729673</td>\n",
       "<td>0.0734796</td>\n",
       "<td>0.1007624</td>\n",
       "<td>0.6218834</td>\n",
       "<td>0.7611969</td>\n",
       "<td>107.2919511</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0227673</td>\n",
       "<td>0.6442984</td>\n",
       "<td>1.7157772</td>\n",
       "<td>0.0226795</td>\n",
       "<td>0.0235567</td>\n",
       "<td>0.0603958</td>\n",
       "<td>0.0609993</td>\n",
       "<td>0.0644275</td>\n",
       "<td>0.6863109</td>\n",
       "<td>-35.5701615</td>\n",
       "<td>71.5777182</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000036</td>\n",
       "<td>0.0217756</td>\n",
       "<td>0.5061977</td>\n",
       "<td>1.4738543</td>\n",
       "<td>0.0178183</td>\n",
       "<td>0.0222234</td>\n",
       "<td>0.0518800</td>\n",
       "<td>0.0532439</td>\n",
       "<td>0.0506216</td>\n",
       "<td>0.7369325</td>\n",
       "<td>-49.3802272</td>\n",
       "<td>47.3854273</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000121</td>\n",
       "<td>0.0209106</td>\n",
       "<td>0.5542494</td>\n",
       "<td>1.3205769</td>\n",
       "<td>0.0195097</td>\n",
       "<td>0.0213446</td>\n",
       "<td>0.0464846</td>\n",
       "<td>0.0479270</td>\n",
       "<td>0.0554296</td>\n",
       "<td>0.7923621</td>\n",
       "<td>-44.5750590</td>\n",
       "<td>32.0576914</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999988</td>\n",
       "<td>0.0201687</td>\n",
       "<td>0.6038306</td>\n",
       "<td>1.2181980</td>\n",
       "<td>0.0212550</td>\n",
       "<td>0.0205365</td>\n",
       "<td>0.0428809</td>\n",
       "<td>0.0440146</td>\n",
       "<td>0.0603750</td>\n",
       "<td>0.8527371</td>\n",
       "<td>-39.6169447</td>\n",
       "<td>21.8198016</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0194045</td>\n",
       "<td>0.5439868</td>\n",
       "<td>1.1339206</td>\n",
       "<td>0.0191485</td>\n",
       "<td>0.0197860</td>\n",
       "<td>0.0399143</td>\n",
       "<td>0.0409860</td>\n",
       "<td>0.0543993</td>\n",
       "<td>0.9071365</td>\n",
       "<td>-45.6013170</td>\n",
       "<td>13.3920599</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999988</td>\n",
       "<td>0.0182818</td>\n",
       "<td>0.4869899</td>\n",
       "<td>1.0620402</td>\n",
       "<td>0.0171422</td>\n",
       "<td>0.0188712</td>\n",
       "<td>0.0373841</td>\n",
       "<td>0.0385288</td>\n",
       "<td>0.0486984</td>\n",
       "<td>0.9558349</td>\n",
       "<td>-51.3010117</td>\n",
       "<td>6.2040181</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0018474</td>\n",
       "<td>0.4416459</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0155460</td>\n",
       "<td>0.0171396</td>\n",
       "<td>0.0352003</td>\n",
       "<td>0.0363899</td>\n",
       "<td>0.0441651</td>\n",
       "<td>1.0</td>\n",
       "<td>-55.8354127</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100071                   0.135878           5.9577    5.9577             0.209712         0.192311   0.209712                    0.192311            0.0596195       0.0596195                  495.77    495.77\n",
       "    2        0.0200022                   0.131042           4.37747   5.16806            0.154088         0.133042   0.181917                    0.162694            0.043753        0.103372                   337.747   416.806\n",
       "    3        0.0300021                   0.128094           4.12121   4.81914            0.145068         0.129395   0.169635                    0.151596            0.0412116       0.144584                   312.121   381.914\n",
       "    4        0.0400019                   0.125603           3.39313   4.46266            0.119439         0.127021   0.157087                    0.145452            0.0339309       0.178515                   239.313   346.266\n",
       "    5        0.0500187                   0.121124           4.02511   4.37503            0.141685         0.123403   0.154002                    0.141037            0.0403187       0.218834                   302.511   337.503\n",
       "    6        0.100001                    0.0780243          2.40073   3.38824            0.0845064        0.106334   0.119267                    0.123692            0.119995        0.338828                   140.073   238.824\n",
       "    7        0.150131                    0.0656007          2.09086   2.95504            0.0735989        0.0705603  0.104018                    0.105951            0.104815        0.443643                   109.086   195.504\n",
       "    8        0.200002                    0.0559375          1.55356   2.60557            0.0546856        0.0610462  0.0917168                   0.0947536           0.0774778       0.521121                   55.3557   160.557\n",
       "    9        0.300004                    0.0245947          1.00761   2.07292            0.0354682        0.0309314  0.0729673                   0.0734796           0.100762        0.621883                   0.761197  107.292\n",
       "    10       0.4                         0.0227673          0.644298  1.71578            0.0226795        0.0235567  0.0603958                   0.0609993           0.0644275       0.686311                   -35.5702  71.5777\n",
       "    11       0.500004                    0.0217756          0.506198  1.47385            0.0178183        0.0222234  0.05188                     0.0532439           0.0506216       0.736932                   -49.3802  47.3854\n",
       "    12       0.600012                    0.0209106          0.554249  1.32058            0.0195097        0.0213446  0.0464846                   0.047927            0.0554296       0.792362                   -44.5751  32.0577\n",
       "    13       0.699999                    0.0201687          0.603831  1.2182             0.021255         0.0205365  0.0428809                   0.0440146           0.060375        0.852737                   -39.6169  21.8198\n",
       "    14       0.8                         0.0194045          0.543987  1.13392            0.0191485        0.019786   0.0399143                   0.040986            0.0543993       0.907136                   -45.6013  13.3921\n",
       "    15       0.899999                    0.0182818          0.48699   1.06204            0.0171422        0.0188712  0.0373841                   0.0385288           0.0486984       0.955835                   -51.301   6.20402\n",
       "    16       1                           0.00184739         0.441646  1                  0.015546         0.0171396  0.0352003                   0.0363899           0.0441651       1                          -55.8354  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.031962353787318085\n",
      "RMSE: 0.1787801828708039\n",
      "LogLoss: 0.13872636623381304\n",
      "Null degrees of freedom: 176934\n",
      "Residual degrees of freedom: 176921\n",
      "Null deviance: 53099.8985915967\n",
      "Residual deviance: 49091.09921915943\n",
      "AIC: 49119.09921915943\n",
      "AUC: 0.6987150470532016\n",
      "pr_auc: 0.11530408549781644\n",
      "Gini: 0.3974300941064033\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.11117014906722764: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>159919.0</td>\n",
       "<td>10912.0</td>\n",
       "<td>0.0639</td>\n",
       "<td> (10912.0/170831.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>4446.0</td>\n",
       "<td>1658.0</td>\n",
       "<td>0.7284</td>\n",
       "<td> (4446.0/6104.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>164365.0</td>\n",
       "<td>12570.0</td>\n",
       "<td>0.0868</td>\n",
       "<td> (15358.0/176935.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      159919  10912  0.0639   (10912.0/170831.0)\n",
       "1      4446    1658   0.7284   (4446.0/6104.0)\n",
       "Total  164365  12570  0.0868   (15358.0/176935.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1111701</td>\n",
       "<td>0.1775731</td>\n",
       "<td>136.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0622521</td>\n",
       "<td>0.2660344</td>\n",
       "<td>233.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.1243162</td>\n",
       "<td>0.1599141</td>\n",
       "<td>103.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7423160</td>\n",
       "<td>0.9660440</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.7940420</td>\n",
       "<td>0.9508197</td>\n",
       "<td>6.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0116402</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9999941</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0671894</td>\n",
       "<td>0.1549918</td>\n",
       "<td>217.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0234451</td>\n",
       "<td>0.6538336</td>\n",
       "<td>328.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0271884</td>\n",
       "<td>0.6698731</td>\n",
       "<td>307.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.11117      0.177573  136\n",
       "max f2                       0.0622521    0.266034  233\n",
       "max f0point5                 0.124316     0.159914  103\n",
       "max accuracy                 0.742316     0.966044  17\n",
       "max precision                0.794042     0.95082   6\n",
       "max recall                   0.0116402    1         398\n",
       "max specificity              1            0.999994  0\n",
       "max absolute_mcc             0.0671894    0.154992  217\n",
       "max min_per_class_accuracy   0.0234451    0.653834  328\n",
       "max mean_per_class_accuracy  0.0271884    0.669873  307"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  3.45 %, avg score:  3.65 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100037</td>\n",
       "<td>0.1355756</td>\n",
       "<td>6.0429963</td>\n",
       "<td>6.0429963</td>\n",
       "<td>0.2084746</td>\n",
       "<td>0.1904411</td>\n",
       "<td>0.2084746</td>\n",
       "<td>0.1904411</td>\n",
       "<td>0.0604522</td>\n",
       "<td>0.0604522</td>\n",
       "<td>504.2996257</td>\n",
       "<td>504.2996257</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200017</td>\n",
       "<td>0.1309905</td>\n",
       "<td>4.4405901</td>\n",
       "<td>5.2420196</td>\n",
       "<td>0.1531939</td>\n",
       "<td>0.1328954</td>\n",
       "<td>0.1808420</td>\n",
       "<td>0.1616764</td>\n",
       "<td>0.0443971</td>\n",
       "<td>0.1048493</td>\n",
       "<td>344.0590070</td>\n",
       "<td>424.2019556</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300054</td>\n",
       "<td>0.1280363</td>\n",
       "<td>3.7011305</td>\n",
       "<td>4.7282931</td>\n",
       "<td>0.1276836</td>\n",
       "<td>0.1293668</td>\n",
       "<td>0.1631192</td>\n",
       "<td>0.1509045</td>\n",
       "<td>0.0370249</td>\n",
       "<td>0.1418742</td>\n",
       "<td>270.1130499</td>\n",
       "<td>372.8293123</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400090</td>\n",
       "<td>0.1253991</td>\n",
       "<td>3.5537403</td>\n",
       "<td>4.4346134</td>\n",
       "<td>0.1225989</td>\n",
       "<td>0.1269452</td>\n",
       "<td>0.1529877</td>\n",
       "<td>0.1449138</td>\n",
       "<td>0.0355505</td>\n",
       "<td>0.1774246</td>\n",
       "<td>255.3740346</td>\n",
       "<td>343.4613449</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500014</td>\n",
       "<td>0.1209271</td>\n",
       "<td>3.7217125</td>\n",
       "<td>4.2921461</td>\n",
       "<td>0.1283937</td>\n",
       "<td>0.1231728</td>\n",
       "<td>0.1480728</td>\n",
       "<td>0.1405690</td>\n",
       "<td>0.0371887</td>\n",
       "<td>0.2146134</td>\n",
       "<td>272.1712507</td>\n",
       "<td>329.2146074</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000028</td>\n",
       "<td>0.0786675</td>\n",
       "<td>2.3000661</td>\n",
       "<td>3.2961061</td>\n",
       "<td>0.0793489</td>\n",
       "<td>0.1065656</td>\n",
       "<td>0.1137109</td>\n",
       "<td>0.1235673</td>\n",
       "<td>0.1150066</td>\n",
       "<td>0.3296199</td>\n",
       "<td>130.0066064</td>\n",
       "<td>229.6106069</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500664</td>\n",
       "<td>0.0659250</td>\n",
       "<td>2.2252175</td>\n",
       "<td>2.9388474</td>\n",
       "<td>0.0767668</td>\n",
       "<td>0.0708538</td>\n",
       "<td>0.1013860</td>\n",
       "<td>0.1059816</td>\n",
       "<td>0.1114024</td>\n",
       "<td>0.4410223</td>\n",
       "<td>122.5217477</td>\n",
       "<td>193.8847439</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0563570</td>\n",
       "<td>1.4501567</td>\n",
       "<td>2.5671691</td>\n",
       "<td>0.0500283</td>\n",
       "<td>0.0613685</td>\n",
       "<td>0.0885636</td>\n",
       "<td>0.0948431</td>\n",
       "<td>0.0724115</td>\n",
       "<td>0.5134338</td>\n",
       "<td>45.0156725</td>\n",
       "<td>156.7169069</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000085</td>\n",
       "<td>0.0246545</td>\n",
       "<td>1.0156413</td>\n",
       "<td>2.0499639</td>\n",
       "<td>0.0350381</td>\n",
       "<td>0.0317317</td>\n",
       "<td>0.0707208</td>\n",
       "<td>0.0738048</td>\n",
       "<td>0.1015727</td>\n",
       "<td>0.6150066</td>\n",
       "<td>1.5641289</td>\n",
       "<td>104.9963914</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0227905</td>\n",
       "<td>0.6422563</td>\n",
       "<td>1.6980668</td>\n",
       "<td>0.0221569</td>\n",
       "<td>0.0235890</td>\n",
       "<td>0.0585808</td>\n",
       "<td>0.0612519</td>\n",
       "<td>0.0642202</td>\n",
       "<td>0.6792267</td>\n",
       "<td>-35.7743717</td>\n",
       "<td>69.8066841</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000028</td>\n",
       "<td>0.0217859</td>\n",
       "<td>0.5356991</td>\n",
       "<td>1.4655880</td>\n",
       "<td>0.0184808</td>\n",
       "<td>0.0222361</td>\n",
       "<td>0.0505607</td>\n",
       "<td>0.0534486</td>\n",
       "<td>0.0535714</td>\n",
       "<td>0.7327982</td>\n",
       "<td>-46.4300853</td>\n",
       "<td>46.5588047</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0209129</td>\n",
       "<td>0.5914322</td>\n",
       "<td>1.3198995</td>\n",
       "<td>0.0204035</td>\n",
       "<td>0.0213486</td>\n",
       "<td>0.0455346</td>\n",
       "<td>0.0480987</td>\n",
       "<td>0.0591415</td>\n",
       "<td>0.7919397</td>\n",
       "<td>-40.8567821</td>\n",
       "<td>31.9899519</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999972</td>\n",
       "<td>0.0201774</td>\n",
       "<td>0.5668574</td>\n",
       "<td>1.2123247</td>\n",
       "<td>0.0195558</td>\n",
       "<td>0.0205398</td>\n",
       "<td>0.0418234</td>\n",
       "<td>0.0441618</td>\n",
       "<td>0.0566841</td>\n",
       "<td>0.8486239</td>\n",
       "<td>-43.3142566</td>\n",
       "<td>21.2324684</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000226</td>\n",
       "<td>0.0194229</td>\n",
       "<td>0.5175617</td>\n",
       "<td>1.1254597</td>\n",
       "<td>0.0178551</td>\n",
       "<td>0.0197969</td>\n",
       "<td>0.0388267</td>\n",
       "<td>0.0411155</td>\n",
       "<td>0.0517693</td>\n",
       "<td>0.9003932</td>\n",
       "<td>-48.2438316</td>\n",
       "<td>12.5459677</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999972</td>\n",
       "<td>0.0182956</td>\n",
       "<td>0.5260184</td>\n",
       "<td>1.0588718</td>\n",
       "<td>0.0181469</td>\n",
       "<td>0.0188850</td>\n",
       "<td>0.0365295</td>\n",
       "<td>0.0386461</td>\n",
       "<td>0.0525885</td>\n",
       "<td>0.9529817</td>\n",
       "<td>-47.3981552</td>\n",
       "<td>5.8871826</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0018230</td>\n",
       "<td>0.4701702</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0162202</td>\n",
       "<td>0.0171745</td>\n",
       "<td>0.0344985</td>\n",
       "<td>0.0364989</td>\n",
       "<td>0.0470183</td>\n",
       "<td>1.0</td>\n",
       "<td>-52.9829800</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100037                   0.135576           6.043     6.043              0.208475         0.190441   0.208475                    0.190441            0.0604522       0.0604522                  504.3     504.3\n",
       "    2        0.0200017                   0.130991           4.44059   5.24202            0.153194         0.132895   0.180842                    0.161676            0.0443971       0.104849                   344.059   424.202\n",
       "    3        0.0300054                   0.128036           3.70113   4.72829            0.127684         0.129367   0.163119                    0.150904            0.0370249       0.141874                   270.113   372.829\n",
       "    4        0.040009                    0.125399           3.55374   4.43461            0.122599         0.126945   0.152988                    0.144914            0.0355505       0.177425                   255.374   343.461\n",
       "    5        0.0500014                   0.120927           3.72171   4.29215            0.128394         0.123173   0.148073                    0.140569            0.0371887       0.214613                   272.171   329.215\n",
       "    6        0.100003                    0.0786675          2.30007   3.29611            0.0793489        0.106566   0.113711                    0.123567            0.115007        0.32962                    130.007   229.611\n",
       "    7        0.150066                    0.065925           2.22522   2.93885            0.0767668        0.0708538  0.101386                    0.105982            0.111402        0.441022                   122.522   193.885\n",
       "    8        0.2                         0.056357           1.45016   2.56717            0.0500283        0.0613685  0.0885636                   0.0948431           0.0724115       0.513434                   45.0157   156.717\n",
       "    9        0.300008                    0.0246545          1.01564   2.04996            0.0350381        0.0317317  0.0707208                   0.0738048           0.101573        0.615007                   1.56413   104.996\n",
       "    10       0.4                         0.0227905          0.642256  1.69807            0.0221569        0.023589   0.0585808                   0.0612519           0.0642202       0.679227                   -35.7744  69.8067\n",
       "    11       0.500003                    0.0217859          0.535699  1.46559            0.0184808        0.0222361  0.0505607                   0.0534486           0.0535714       0.732798                   -46.4301  46.5588\n",
       "    12       0.6                         0.0209129          0.591432  1.3199             0.0204035        0.0213486  0.0455346                   0.0480987           0.0591415       0.79194                    -40.8568  31.99\n",
       "    13       0.699997                    0.0201774          0.566857  1.21232            0.0195558        0.0205398  0.0418234                   0.0441618           0.0566841       0.848624                   -43.3143  21.2325\n",
       "    14       0.800023                    0.0194229          0.517562  1.12546            0.0178551        0.0197969  0.0388267                   0.0411155           0.0517693       0.900393                   -48.2438  12.546\n",
       "    15       0.899997                    0.0182956          0.526018  1.05887            0.0181469        0.018885   0.0365295                   0.0386461           0.0525885       0.952982                   -47.3982  5.88718\n",
       "    16       1                           0.00182302         0.47017   1                  0.0162202        0.0171745  0.0344985                   0.0364989           0.0470183       1                          -52.983   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>negative_log_likelihood</b></td>\n",
       "<td><b>objective</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-08-02 16:22:25</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0</td>\n",
       "<td>63024.3343252</td>\n",
       "<td>0.1523781</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-08-02 16:22:25</td>\n",
       "<td> 0.202 sec</td>\n",
       "<td>1</td>\n",
       "<td>59410.1158804</td>\n",
       "<td>0.1475106</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-08-02 16:22:25</td>\n",
       "<td> 0.315 sec</td>\n",
       "<td>2</td>\n",
       "<td>58668.3644981</td>\n",
       "<td>0.1431184</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-08-02 16:22:25</td>\n",
       "<td> 0.419 sec</td>\n",
       "<td>3</td>\n",
       "<td>58051.4092846</td>\n",
       "<td>0.1423422</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    iterations    negative_log_likelihood    objective\n",
       "--  -------------------  ----------  ------------  -------------------------  -----------\n",
       "    2019-08-02 16:22:25  0.000 sec   0             63024.3                    0.152378\n",
       "    2019-08-02 16:22:25  0.202 sec   1             59410.1                    0.147511\n",
       "    2019-08-02 16:22:25  0.315 sec   2             58668.4                    0.143118\n",
       "    2019-08-02 16:22:25  0.419 sec   3             58051.4                    0.142342"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_model_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7038748631916821"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_model_reg.auc(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6987150470532016"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_model_reg.auc(valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_924f closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
